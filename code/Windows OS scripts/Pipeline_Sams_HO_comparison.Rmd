---
output: 
  html_document: 
    toc: true
---

# 0: Preparation
Defining the input and output files

```{r setup,echo = FALSE}

#echo = FALSE # Hides the code.
#results = 'hide' # Hides the output of the code.
#message = FALSE # Hides any messages generated by the code.
#warning = FALSE # Hides any warnings generated by the code.

# Clean the working environment
rm(list = ls())


# empirical_species <- "German Shepherd"
empirical_species <- "Labrador Retriever"


document_title <- paste(empirical_species," Pipeline Results")

MAF_pruning_used <- FALSE

N_e <- 50

if (MAF_pruning_used == FALSE) {
  document_sub <- paste("No MAF-based pruning used, N_e =", N_e)
} else {
  document_sub <- paste("MAF-based pruning used, N_e =", N_e)
}


knitr::opts_chunk$set(echo = TRUE)


############################################ 
# Parameters used for displaying the result
############################################ 
ROH_frequency_decimals <- 1
H_e_values_decimals <- 3
F_ROH_values_decimals <- 3
Window_lengths_decimals <- 2
Error_percentage_decimals <- 1
Standard_deviation_decimals <- 5

empirical_dog_breed <- "labrador_retriever"


####################################  
# Defining the working directory
#################################### 

# Set the path to your GitHub folder
YOUR_GITHUB_ROOT_DIRECTORY <- "C:/Users/jonat/GitHub"

# Defining the relative path in the repository
repository_path <- file.path(YOUR_GITHUB_ROOT_DIRECTORY,"Computational-modelling-of-genomic-inbreeding-and-roh-islands-in-extremely-small-populations")


####################################  
# Defining the input file
#################################### 
# simulated_data_dir_basename <- "simulated - HO5"
#simulated_data_dir_basename <- "simulated - HO6"
# simulated_data_dir_basename <- "simulated - HO7_V1"
# simulated_data_dir_HO_basename <- "simulated - HO7_v2"
# simulated_data_dir_HO_basename <- "simulated - HO9_V1"
# simulated_data_dir_HO_basename <- "simulated - HO9_V2"
# simulated_data_dir_HO_basename <- "simulated - H10_V1"
# simulated_data_dir_HO_basename <- "simulated - HO11_6"
# simulated_data_dir_HO_basename <- "simulated - HO14_V1"
# simulated_data_dir_HO_basename <- "simulated - HO14_V3"
simulated_data_dir_HO_basename <- "simulated - HO15_1"

simulated_data_dir_SAMS_basename <- "simulated - Sams"
# simulated_data_dir_basename <- "simulated - Sams"


#results_dir <- file.path(repository_path,"results - innan 24 maj")
# results_dir <- file.path(repository_path,"results")
# results_dir <- file.path(repository_path,"res_HO5")
# results_dir <- file.path(repository_path,"res_HO6")
# results_dir <- file.path(repository_path,"res_HO7_v1")
# results_dir_HO <- file.path(repository_path,"res_HO7_v2")
# results_dir_HO <- file.path(repository_path,"res_HO9_v1")
# results_dir_HO <- file.path(repository_path,"res_HO9_v2")
# results_dir_HO <- file.path(repository_path,"res_H10_v1")
# results_dir_HO <- file.path(repository_path,"res_HO11_6")
# results_dir_HO <- file.path(repository_path,"res_HO14_1")
# results_dir_HO <- file.path(repository_path,"res_HO14_3")
results_dir_HO <- file.path(repository_path,"resH15_1")
results_dir_SAMS <- file.path(repository_path,"rSams")

# results_dir <- file.path(repository_path,"results-50")
# results_dir <- file.path(repository_path,"results_50")
# results_dir <- file.path(repository_path,"results_lab")


plink_ROH_dir_HO <- file.path(results_dir_HO,"PLINK//ROH")
expected_heterozygosity_dir_NO_MAF_HO <- file.path(results_dir_HO,"expected_heterozygosity_No_MAF")
# expected_heterozygosity_dir_NO_MAF_HO <- file.path(results_dir_HO,"expected_heterozygosity_MAF_0_01")
expected_heterozygosity_dir_MAF_0_05_HO <- file.path(results_dir_HO,"expected_heterozygosity_MAF_0_05")

plink_ROH_dir_SAMS <- file.path(results_dir_SAMS,"PLINK//ROH")
expected_heterozygosity_dir_NO_MAF_SAMS <- file.path(results_dir_SAMS,"expected_heterozygosity_No_MAF")
expected_heterozygosity_dir_MAF_0_05_SAMS <- file.path(results_dir_SAMS,"expected_heterozygosity_MAF_0_05")
# expected_heterozygosity_dir_NO_MAF_SAMS <- file.path(results_dir_SAMS,"expected_heterozygosity_MAF_0_01")
# expected_heterozygosity_dir_NO_MAF_SAMS <- file.path(results_dir_SAMS,"expected_heterozygosity_MAF_0_05")


ROH_hotspots_dir_HO <- file.path(results_dir_HO,"ROH-Hotspots")
ROH_hotspots_dir_SAMS <- file.path(results_dir_SAMS,"ROH-Hotspots")

Selection_strength_test_dir_HO <- file.path(ROH_hotspots_dir_HO,"selection_strength_test_No_MAF")
# Selection_strength_test_dir_HO <- file.path(ROH_hotspots_dir_HO,"selection_strength_test_MAF_0_01")
# Selection_strength_test_dir_HO <- file.path(ROH_hotspots_dir_HO,"selection_strength_test_MAF_0_05")


Sweep_test_dir_HO <- file.path(ROH_hotspots_dir_HO,"sweep_test_No_MAF")
# Sweep_test_dir_HO <- file.path(results_dir_HO,"sweep_test_MAF_0_01")
# Sweep_test_dir_HO <- file.path(results_dir_HO,"sweep_test_MAF_0_05")


Selection_strength_test_dir_SAMS <- file.path(ROH_hotspots_dir_SAMS,"selection_strength_test_No_MAF")
# Selection_strength_test_dir_SAMS <- file.path(ROH_hotspots_dir_SAMS,"selection_strength_test_MAF_0_01")
# Selection_strength_test_dir_SAMS <- file.path(ROH_hotspots_dir_SAMS,"selection_strength_test_MAF_0_05")

# 
Sweep_test_dir_SAMS <- file.path(ROH_hotspots_dir_SAMS,"sweep_test_No_MAF")
# Sweep_test_dir_SAMS <- file.path(results_dir_SAMS,"sweep_test_MAF_0_01")
# Sweep_test_dir_SAMS <- file.path(results_dir_SAMS,"sweep_test_MAF_0_05")




#¤¤¤¤¤¤¤¤ Simulated Data ¤¤¤¤¤¤¤¤
raw_data_dir <- file.path(repository_path,"data/raw")
# raw_data_dir <- file.path(repository_path,"dataa/raw")
raw_simulated_data_dir_HO <- file.path(raw_data_dir,simulated_data_dir_HO_basename)
raw_simulated_data_dir_SAMS <- file.path(raw_data_dir,simulated_data_dir_SAMS_basename)
# raw_simulated_data_dir <- file.path(raw_data_dir,"simulated_Mats_No_MAF_pruning_50_N_e")
# raw_simulated_data_dir <- file.path(raw_data_dir,"simulated_Mats_No_MAF_pruning_70_N_e")

############### 
## Empirical ###
###############

### ROH hotspots ###
Empirical_data_ROH_hotspots_dir  <- file.path(ROH_hotspots_dir_HO,"empirical",empirical_dog_breed)
Empirical_data_autosome_ROH_freq_dir <- file.path(Empirical_data_ROH_hotspots_dir,"Gosling_plots/autosome_roh_freq")
### Inbreeding coefficient ###

Empirical_data_F_ROH_dir  <- file.path(plink_ROH_dir_HO,"empirical",empirical_dog_breed,"F_ROH")

### Expected Heterozygosity distribution ###
Empirical_data_H_e_dir_NO_MAF <- file.path(expected_heterozygosity_dir_NO_MAF_HO,"empirical",empirical_dog_breed)
Empirical_data_H_e_dir_MAF_0_05 <- file.path(expected_heterozygosity_dir_MAF_0_05_HO,"empirical",empirical_dog_breed)
############### 
## Simulated ###
###############

### ROH hotspots ###
Neutral_model_ROH_hotspots_dir_HO  <- file.path(ROH_hotspots_dir_HO,"simulated/neutral")
Neutral_model_autosome_ROH_freq_dir_HO <- file.path(Neutral_model_ROH_hotspots_dir_HO,"Gosling_plots/autosome_roh_freq")

Selection_model_ROH_hotspots_dir_HO  <- file.path(ROH_hotspots_dir_HO,"simulated/selection")
Selection_model_autosome_ROH_freq_dir_HO <- file.path(Selection_model_ROH_hotspots_dir_HO,"Gosling_plots/autosome_roh_freq")

Neutral_model_ROH_hotspots_dir_SAMS  <- file.path(ROH_hotspots_dir_SAMS,"simulated/neutral")
Neutral_model_autosome_ROH_freq_dir_SAMS <- file.path(Neutral_model_ROH_hotspots_dir_SAMS,"Gosling_plots/autosome_roh_freq")

Selection_model_ROH_hotspots_dir_SAMS  <- file.path(ROH_hotspots_dir_SAMS,"simulated/selection")
Selection_model_autosome_ROH_freq_dir_SAMS <- file.path(Selection_model_ROH_hotspots_dir_SAMS,"Gosling_plots/autosome_roh_freq")



### Inbreeding coefficient ###
Neutral_model_F_ROH_dir_HO  <- file.path(plink_ROH_dir_HO,"simulated/neutral_model/F_ROH")
Selection_model_F_ROH_dir_HO  <- file.path(plink_ROH_dir_HO,"simulated/selection_model/F_ROH")

Neutral_model_F_ROH_dir_SAMS  <- file.path(plink_ROH_dir_SAMS,"simulated/neutral_model/F_ROH")
Selection_model_F_ROH_dir_SAMS  <- file.path(plink_ROH_dir_SAMS,"simulated/selection_model/F_ROH")

### Expected Heterozygosity distribution ###
Neutral_model_H_e_dir_HO <- file.path(expected_heterozygosity_dir_NO_MAF_HO,"simulated/neutral_model")
Selection_model_H_e_dir_HO <- file.path(expected_heterozygosity_dir_NO_MAF_HO,"simulated/selection_model")

Neutral_model_H_e_dir_MAF_0_05_HO <- file.path(expected_heterozygosity_dir_MAF_0_05_HO,"simulated/neutral_model")


raw_selection_dir_HO <- file.path(raw_simulated_data_dir_HO,"selection_model")

Neutral_model_H_e_dir_SAMS <- file.path(expected_heterozygosity_dir_NO_MAF_SAMS,"simulated/neutral_model")

Neutral_model_H_e_dir_MAF_0_05_SAMS <- file.path(expected_heterozygosity_dir_MAF_0_05_SAMS,"simulated/neutral_model")

Selection_model_H_e_dir_SAMS <- file.path(expected_heterozygosity_dir_NO_MAF_SAMS,"simulated/selection_model")

raw_selection_dir_SAMS <- file.path(raw_simulated_data_dir_SAMS,"selection_model")

histogram_line_sizes <- 3
empirical_data_color <- "darkgreen"
neutral_model_color <- "blue" 
selection_model_color <- "purple"

# #################################### 
# # Defining the output dirs
# #################################### 
output_dir <- file.path(repository_path,"Pipeline_results_comparison")

if (!dir.exists(output_dir)) {
  # Create the directory
  dir.create(output_dir, recursive = TRUE)
}


```

---
title: "`r document_title`"
subtitle: "`r document_sub`"
output:
  html_document:
    toc: true
    toc_depth: 3  
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
---

## Loading libraries
```{r library()}
library(knitr)
library(ggplot2)
# Install and load the scatterplot3d package
# install.packages("scatterplot3d")
library(scatterplot3d)
library(RColorBrewer) # For generating a color palette
```
# Latex formatting function
```{r ,echo = FALSE}
# Function to format and write a data frame to a LaTeX-compatible text file
write_latex_table <- function(data_frame, sort_column, output_dir, output_filename) {
  
  # Sort the data frame based on the specified column
  sorted_df <- data_frame[order(data_frame[[sort_column]]), ]
  
  # Define the complete file path
  file_path <- file.path(output_dir, paste(output_filename, ".txt", sep = ""))
  
  # Open a connection to the file for writing
  file_conn <- file(file_path, open = "wt")
  
  # Loop through each row in the sorted DataFrame
  for (i in 1:nrow(sorted_df)) {
    # Format the row with & separator and \\ at the end
    formatted_row <- paste(sorted_df[i, ], collapse = " & ")
    formatted_row <- paste(formatted_row, "\\\\", sep = "")
    
    # Write the formatted row to the file
    cat(formatted_row, file = file_conn, sep = "\n")
  }
  
  # Close the file connection
  close(file_conn)
  
  # Return the file path for reference
  return(file_path)
}

```

# Standard Error Confidence interval function
Confidence level <=> konfidensgrad
```{r}
# Function to calculate standard error and its confidence interval
standard_error_confidence_interval_fun <- function(observed_data, confidence_level = 0.95) {
  # if ( nrow(observed_data) > 1 ) {
  
  if ( length(observed_data) > 1 ) {
      
  # Calculate standard error
  n <- length(observed_data)
  standard_deviation <- sd(observed_data)
  standard_error <- standard_deviation / sqrt(n - 1)
  
  # Calculate confidence interval based on standard error

  alpha <- (1 - confidence_level) / 2
  margin_of_error <- qnorm(1 - alpha) * standard_error
  mean_estimate <- mean(observed_data)
  # Calculate the percentiles for the confidence interval
  confidence_interval_lower_bound <- mean_estimate - margin_of_error # 2.5th percentile (2σ)
  confidence_interval_upper_bound <- mean_estimate + margin_of_error # 97.5th percentile (2σ)
  
  # Return confidence interval
  return(c(confidence_interval_lower_bound, confidence_interval_upper_bound))

    
  } else {
    return(c(NA,NA)) 
    }
  
  
} 

```
# Standard deviation
```{r}
# Function to calculate standard error and its confidence interval
standard_deviation_fun <- function(observed_data, confidence_level = 0.95) {

  if ( length(observed_data) > 1 ) {
  # Calculate standard error
  n <- length(observed_data)
  standard_deviation <- sd(observed_data)
 
  # Return the standard deviation
  return(standard_deviation)

    
  } else {
    return(Na) 
    }
  
  
} 


```



# 1: ROH-Frequency
## 1.1 : Autosome ROH-frequencies
### 1.1.1 : Empirical - ROH frequency
```{r Empirical - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
setwd(Empirical_data_autosome_ROH_freq_dir)

# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- ".*ROH_freq.*\\.tsv$"
population_ROH_freq_files <- list.files(path = Empirical_data_autosome_ROH_freq_dir, pattern = pattern)
#population_ROH_freq_files
# Extracting the ROH-hotspot threshold value from the suffix of the filename
parts <- unlist(strsplit(population_ROH_freq_files[1], "threshold_")) # Split the string by "threshold_"
# Extract the decimal number using regular expressions
Empirical_data_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))

# Extract chromosome numbers from filenames
chr_numbers <- as.numeric(gsub(tolower(".*CHR(\\d+)_.*"), "\\1", tolower(population_ROH_freq_files)))
# cat("CHR Values:", chr_numbers, "\n")
# Sort filenames based on chromosome numbers
sorted_population_ROH_freq_files <- population_ROH_freq_files[order(chr_numbers)]
# Initialize an empty list to store the ROH-frequency data
ROH_freq_table_Empirical_Data <- list()
# Loop through each sorted .tsv file
for (file in sorted_population_ROH_freq_files) {
  file_name <- file
  ROH_freq_data <- read.table(file, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add chromosome_name as an attribute to the data frame
  chr_num <- as.numeric(gsub(tolower(".*CHR(\\d+)_.*"), "\\1", tolower(file)))
  attr(ROH_freq_data, "chromosome_name") <- chr_num
  # Create a list with table name and corresponding data frame
  table_info <- list(chromosome_name = chr_num, filename = file_name, data = ROH_freq_data)  # Added chromosome_name here
  # Append the table info to the list
  ROH_freq_table_Empirical_Data <- c(ROH_freq_table_Empirical_Data, list(table_info))
}
ROH_freq_table_Empirical_Data$ROH_hotspot_threshold <- Empirical_data_ROH_hotspot_threshold
# View(ROH_freq_table_Empirical_Data)
```
### 1.1.2: HO Neutral Model - ROH frequency
```{r HO Neutral Model - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
setwd(Neutral_model_autosome_ROH_freq_dir_HO)
# Pattern for finding files containing "F_ROH" and ending with """.tsv"""
pattern <- ".*ROH_freq.*\\.tsv$"
neutral_model_ROH_freq_files_HO <- list.files(path = Neutral_model_autosome_ROH_freq_dir_HO, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(neutral_model_ROH_freq_files_HO)))
# cat("CHR Values:", chr_numbers, "\n")
# Sort filenames based on chromosome numbers
sorted_neutral_model_ROH_freq_files_HO <- neutral_model_ROH_freq_files_HO[order(sim_numbers)]
# Initialize an empty list to store the ROH-frequency data
ROH_freq_tables_Neutral_Model_HO <- list()
# Loop through each sorted .tsv file
for (file in sorted_neutral_model_ROH_freq_files_HO) {
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add chromosome_name as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file, data = ROH_freq_data,ROH_Hotspot_threshold = simulation_ROH_hotspot_threshold)  # Added chromosome_name here
  # Append the table info to the list
  ROH_freq_tables_Neutral_Model_HO <- c(ROH_freq_tables_Neutral_Model_HO, list(table_info))
}
# Extract all ROH-hotspot thresholds from ROH_freq_tables_Neutral_Model_HO
all_ROH_hotspot_thresholds <- unlist(lapply(ROH_freq_tables_Neutral_Model_HO, function(table) table$ROH_Hotspot_threshold))
# Calculate the overall average F_ROH
Avg_ROH_hotspot_threshold <- mean(all_ROH_hotspot_thresholds)
ROH_freq_tables_Neutral_Model_HO$Avg_ROH_hotspot_threshold <- Avg_ROH_hotspot_threshold

# Calculate the confidence interval of the point estimate ROH-hotspot threshold across all 20 simulations
ROH_freq_tables_Neutral_Model_HO$SE_CI_ROH_hotspot_threshold <- standard_error_confidence_interval_fun(all_ROH_hotspot_thresholds)
ROH_freq_tables_Neutral_Model_HO$Standard_deviation <- standard_deviation_fun(all_ROH_hotspot_thresholds)

# View(ROH_freq_tables_Neutral_Model_HO)

```
### 1.1.2 SAMS Neutral Model - ROH frequency
```{r}
setwd(Neutral_model_autosome_ROH_freq_dir_SAMS)
# Pattern for finding files containing "F_ROH" and ending with """.tsv"""
pattern <- ".*ROH_freq.*\\.tsv$"
neutral_model_ROH_freq_files_SAMS <- list.files(path = Neutral_model_autosome_ROH_freq_dir_SAMS, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(neutral_model_ROH_freq_files_SAMS)))
# cat("CHR Values:", chr_numbers, "\n")
# Sort filenames based on chromosome numbers
sorted_neutral_model_ROH_freq_files_SAMS <- neutral_model_ROH_freq_files_SAMS[order(sim_numbers)]
# Initialize an empty list to store the ROH-frequency data
ROH_freq_tables_Neutral_Model_SAMS <- list()
# Loop through each sorted .tsv file
for (file in sorted_neutral_model_ROH_freq_files_SAMS) {
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add chromosome_name as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file, data = ROH_freq_data,ROH_Hotspot_threshold = simulation_ROH_hotspot_threshold)  # Added chromosome_name here
  # Append the table info to the list
  ROH_freq_tables_Neutral_Model_SAMS <- c(ROH_freq_tables_Neutral_Model_SAMS, list(table_info))
}
# Extract all ROH-hotspot thresholds from ROH_freq_tables_Neutral_Model_SAMS
all_ROH_hotspot_thresholds <- unlist(lapply(ROH_freq_tables_Neutral_Model_SAMS, function(table) table$ROH_Hotspot_threshold))
# Calculate the overall average F_ROH
Avg_ROH_hotspot_threshold <- mean(all_ROH_hotspot_thresholds)
ROH_freq_tables_Neutral_Model_SAMS$Avg_ROH_hotspot_threshold <- Avg_ROH_hotspot_threshold

# Calculate the confidence interval of the point estimate ROH-hotspot threshold across all 20 simulations
ROH_freq_tables_Neutral_Model_SAMS$SE_CI_ROH_hotspot_threshold <- standard_error_confidence_interval_fun(all_ROH_hotspot_thresholds)
ROH_freq_tables_Neutral_Model_SAMS$Standard_deviation <- standard_deviation_fun(all_ROH_hotspot_thresholds)
# View(ROH_freq_tables_Neutral_Model_SAMS)

```
### 1.1.3: HO Selection Model
```{r HO Selection Model - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
# Set the working directory to the directory containing the selection model ROH frequency files
setwd(Selection_model_autosome_ROH_freq_dir_HO)
# Pattern for finding files containing "ROH_freq" and ending with ".tsv"
pattern <- ".*ROH_freq.*\\.tsv$"
selection_model_ROH_freq_files_HO <- list.files(path = Selection_model_autosome_ROH_freq_dir_HO, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(selection_model_ROH_freq_files_HO)))
sim_name <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(selection_model_ROH_freq_files_HO))
# Preallocate sim_info as an empty data frame
sim_info <- data.frame(sim_name = character(), simulation_number = numeric(), file_name = character(), stringsAsFactors = FALSE)
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = sim_numbers, file_name =selection_model_ROH_freq_files_HO)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store the selection model tables
ROH_freq_tables_Selection_Model_HO <- list()
# Loop through each sorted .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(file))
  
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    print(paste0("simname_from_file:", simname_from_file))
    print(paste0("sim_info$sim_name[i]:", sim_info$sim_name[i]))
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(ROH_freq_tables_Selection_Model_HO))) {
    # If it doesn't exist, create a list for it
    ROH_freq_tables_Selection_Model_HO[[selection_coefficient]] <- list()
  }
  table_info
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file,ROH_Hotspot_threshold =    simulation_ROH_hotspot_threshold, data = ROH_freq_data)  # Added ROH_Hotspot_threshold here
  # Append the table info to the list under selection_coefficient
  ROH_freq_tables_Selection_Model_HO[[selection_coefficient]] <- c(ROH_freq_tables_Selection_Model_HO[[selection_coefficient]], list(table_info))
}
# Calculate overall average ROH hotspot threshold for each selection coefficient
for (selection_coefficient in names(ROH_freq_tables_Selection_Model_HO)) {
  all_thresholds <- unlist(lapply(ROH_freq_tables_Selection_Model_HO[[selection_coefficient]], function(table) table$ROH_Hotspot_threshold))
  overall_avg_threshold <- mean(all_thresholds)
  ROH_freq_tables_Selection_Model_HO[[selection_coefficient]]$Avg_ROH_hotspot_threshold <- overall_avg_threshold
}
# View the resulting nested structure
# View(ROH_freq_tables_Selection_Model_HO)
```
### 1.1.3: Sams Selection Model
```{r Sams Selection Model - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
# Set the working directory to the directory containing the selection model ROH frequency files
setwd(Selection_model_autosome_ROH_freq_dir_SAMS)
# Pattern for finding files containing "ROH_freq" and ending with ".tsv"
pattern <- ".*ROH_freq.*\\.tsv$"
selection_model_ROH_freq_files_SAMS <- list.files(path = Selection_model_autosome_ROH_freq_dir_SAMS, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(selection_model_ROH_freq_files_SAMS)))
sim_name <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(selection_model_ROH_freq_files_SAMS))
# Preallocate sim_info as an empty data frame
sim_info <- data.frame(sim_name = character(), simulation_number = numeric(), file_name = character(), stringsAsFactors = FALSE)
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = sim_numbers, file_name =selection_model_ROH_freq_files_SAMS)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store the selection model tables
ROH_freq_tables_Selection_Model_SAMS <- list()
# Loop through each sorted .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(file))
  
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    print(paste0("simname_from_file:", simname_from_file))
    print(paste0("sim_info$sim_name[i]:", sim_info$sim_name[i]))
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(ROH_freq_tables_Selection_Model_SAMS))) {
    # If it doesn't exist, create a list for it
    ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]] <- list()
  }
  table_info
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file,ROH_Hotspot_threshold =    simulation_ROH_hotspot_threshold, data = ROH_freq_data)  # Added ROH_Hotspot_threshold here
  # Append the table info to the list under selection_coefficient
  ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]] <- c(ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]], list(table_info))
}
# Calculate overall average ROH hotspot threshold for each selection coefficient
for (selection_coefficient in names(ROH_freq_tables_Selection_Model_SAMS)) {
  all_thresholds <- unlist(lapply(ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]], function(table) table$ROH_Hotspot_threshold))
  overall_avg_threshold <- mean(all_thresholds)
  ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]]$Avg_ROH_hotspot_threshold <- overall_avg_threshold
}
# View the resulting nested structure
# View(ROH_freq_tables_Selection_Model_SAMS)
```





### 1.1.4 Summary - ROH-hotspot threshold 

```{r echo = FALSE,warning = FALSE}
# cat("ROH-hotspot selection testing results://n")
# 
# # Initialize an empty vector to store F_ROH values for the different selection coefficients
# selection_model_values_list_HO <- c()
# selection_model_names_list_HO <- c()
# 
# # Loop through each selection_coefficient in ROH_freq_tables_Selection_Model
# for (selection_coefficient in names(ROH_freq_tables_Selection_Model_HO)) {
#   # Extract the Avg_ROH_hotspot_threshold value from the selection_coefficient
#   Avg_ROH_hotspot_threshold <- round(100*ROH_freq_tables_Selection_Model_HO[[selection_coefficient]]$Avg_ROH_hotspot_threshold,ROH_frequency_decimals)
# 
#   # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
#   formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_coefficient)
# 
#   # Append values to the lists
#   selection_model_values_list_HO <- c(selection_model_values_list_HO, Avg_ROH_hotspot_threshold)
#   selection_model_names_list_HO <- c(selection_model_names_list_HO, formatted_selection_coefficient_labels)
# }
# 
# # Initialize an empty vector to store F_ROH values for the different selection coefficients
# selection_model_values_list_SAMS <- c()
# selection_model_names_list_SAMS <- c()
# 
# # Loop through each selection_coefficient in ROH_freq_tables_Selection_Model
# for (selection_coefficient in names(ROH_freq_tables_Selection_Model_SAMS)) {
#   # Extract the Avg_ROH_hotspot_threshold value from the selection_coefficient
#   Avg_ROH_hotspot_threshold <- round(100*ROH_freq_tables_Selection_Model_SAMS[[selection_coefficient]]$Avg_ROH_hotspot_threshold,ROH_frequency_decimals)
# 
#   # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
#   formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_coefficient)
# 
#   # Append values to the lists
#   selection_model_values_list_SAMS <- c(selection_model_values_list_SAMS, Avg_ROH_hotspot_threshold)
#   selection_model_names_list_SAMS <- c(selection_model_names_list_SAMS, formatted_selection_coefficient_labels)
# }

# Add overAvg_ROH_hotspot_threshold from ROH_freq_tables_Neutral_Model_HO
neutral_model_value_HO <- round(100*ROH_freq_tables_Neutral_Model_HO[["Avg_ROH_hotspot_threshold"]],ROH_frequency_decimals)
neutral_model_HO_error_perc <- round(100*( abs( 1-(ROH_freq_tables_Neutral_Model_HO[["Avg_ROH_hotspot_threshold"]]/ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]])))
                                     ,ROH_frequency_decimals)

# neutral_lower_ci <- round(100*ROH_freq_tables_Neutral_Model$SE_CI_ROH_hotspot_threshold[1],ROH_frequency_decimals)
neutral_HO_lower_ci <- round(100*ROH_freq_tables_Neutral_Model_HO[["SE_CI_ROH_hotspot_threshold"]][1],ROH_frequency_decimals)
neutral_HO_upper_ci <- round(100*ROH_freq_tables_Neutral_Model_HO[["SE_CI_ROH_hotspot_threshold"]][2],ROH_frequency_decimals)
neutral_HO_standard_deviation <- round(100*ROH_freq_tables_Neutral_Model_HO[["Standard_deviation"]],ROH_frequency_decimals)
neutral_HO_Coefficient_of_Variation <- 100*(neutral_HO_standard_deviation/neutral_model_value_HO)



neutral_model_SAMS_error_perc <- round(100*( abs( 1-(ROH_freq_tables_Neutral_Model_SAMS[["Avg_ROH_hotspot_threshold"]]/ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]])))
                                     ,ROH_frequency_decimals)

# Add overAvg_ROH_hotspot_threshold from ROH_freq_tables_Neutral_Model_SAMS
neutral_model_value_SAMS <- round(100*ROH_freq_tables_Neutral_Model_SAMS[["Avg_ROH_hotspot_threshold"]],ROH_frequency_decimals)
neutral_SAMS_lower_ci <- round(100*ROH_freq_tables_Neutral_Model_SAMS[["SE_CI_ROH_hotspot_threshold"]][1],ROH_frequency_decimals)
neutral_SAMS_upper_ci <- round(100*ROH_freq_tables_Neutral_Model_SAMS[["SE_CI_ROH_hotspot_threshold"]][2],ROH_frequency_decimals)
neutral_SAMS_standard_deviation <- round(100*ROH_freq_tables_Neutral_Model_SAMS[["Standard_deviation"]],ROH_frequency_decimals)
neutral_SAMS_Coefficient_of_Variation <- 100*(neutral_SAMS_standard_deviation/neutral_model_value_SAMS)

# Add Avg_ROH_hotspot_threshold from ROH_freq_table_Empirical_Data
empirical_model_value <- round(100*ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]],ROH_frequency_decimals)
empirical_HO_error_perc <- NA # Placeholder for confidence interval upper bound
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
empirical_ci_width_percentage_ROH_hotspot_thr <- NA # Placeholder value
empirical_standard_deviation <- NA # Placeholder value
empirical_Coefficient_of_Variation <- NA # Placeholder value

# # Combine all values into a data frame
# ROH_hotspot_threshold_values <- data.frame(
#   Model = c(rep("Selection", length(selection_model_values_list_HO)), "Neutral", "Empirical"),
#   ROH_hotspot_thr = c(selection_model_values_list_HO, neutral_model_value_HO, empirical_model_value)
# )
######################## H_E - NO MAF ######################## 
# neutral_ROH_hotspot_thr_CI_width_HO <- neutral_HO_upper_ci - neutral_HO_lower_ci
# Calculate CI width percentage for the average ROH-hotspot
# ci_width_percentage_ROH_hotspot_thr_HO <- ifelse(neutral_ROH_hotspot_thr_CI_width_HO == 0, 
#                                                  0, 
#                                                  100*(neutral_ROH_hotspot_thr_CI_width_HO / neutral_model_value_HO))
# ci_width_percentage_ROH_hotspot_thr_HO <- ifelse(neutral_ROH_hotspot_thr_CI_width_HO == 0, 
#                                                  0, 
#                                                  100*(neutral_ROH_hotspot_thr_CI_width_HO / empirical_model_value))
# 
# 
# neutral_ROH_hotspot_thr_CI_width_SAMS <- neutral_SAMS_upper_ci - neutral_SAMS_lower_ci
# # Calculate CI width percentage for the average ROH-hotspot
# ci_width_percentage_ROH_hotspot_thr_SAMS <- ifelse(neutral_ROH_hotspot_thr_CI_width_SAMS == 0, 
#                                                  0, 
#                                           100*(neutral_ROH_hotspot_thr_CI_width_SAMS / empirical_model_value))




# Combine all values into a data frame
ROH_hotspot_threshold_values <- data.frame(
  Model = c("Neutral Sams","Neutral HO" , "Empirical"),
  ROH_hotspot_thr = c(neutral_model_value_SAMS,neutral_model_value_HO, empirical_model_value),
  Lower_CI = c(neutral_SAMS_lower_ci, neutral_HO_lower_ci , empirical_lower_ci),
  Upper_CI = c(neutral_SAMS_upper_ci, neutral_HO_upper_ci , empirical_upper_ci),
  Standard_Deviation = c(neutral_SAMS_standard_deviation, neutral_HO_standard_deviation ,empirical_standard_deviation),
  Coefficient_of_variation = c(neutral_SAMS_Coefficient_of_Variation,neutral_HO_Coefficient_of_Variation,empirical_Coefficient_of_Variation),
  Error_percentage = c(neutral_model_SAMS_error_perc,neutral_model_HO_error_perc,empirical_HO_error_perc)
)
# ROH_hotspot_threshold_values$CI_width_perc <- round(ROH_hotspot_threshold_values$CI_width_perc,Error_percentage_decimals)




# # Combine all values into a data frame
# ROH_hotspot_threshold_values <- data.frame(
#   Model = c("Neutral Sams","Neutral HO" , "Empirical"),
#   ROH_hotspot_thr = c(neutral_model_value_SAMS,neutral_model_value_HO, empirical_model_value),
#   Lower_CI = c(neutral_SAMS_lower_ci, neutral_HO_lower_ci , empirical_lower_ci),
#   Upper_CI = c(neutral_SAMS_upper_ci, neutral_HO_upper_ci , empirical_upper_ci),
#   CI_width_perc = c(ci_width_percentage_ROH_hotspot_thr_SAMS, ci_width_percentage_ROH_hotspot_thr_HO ,empirical_ci_width_percentage_ROH_hotspot_thr),
#   Error_percentage = c(neutral_model_SAMS_error_perc,neutral_model_HO_error_perc,empirical_HO_error_perc)
# )
# ROH_hotspot_threshold_values$CI_width_perc <- round(ROH_hotspot_threshold_values$CI_width_perc,Error_percentage_decimals)

ROH_hotspot_threshold_values$Standard_Deviation <- round(ROH_hotspot_threshold_values$Standard_Deviation,Standard_deviation_decimals)
ROH_hotspot_threshold_values$Error_percentage <- round(ROH_hotspot_threshold_values$Error_percentage,Error_percentage_decimals)
ROH_hotspot_threshold_values$Coefficient_of_variation <- round(ROH_hotspot_threshold_values$Coefficient_of_variation,Error_percentage_decimals)
# # Update the Model column for selection models
# ROH_hotspot_threshold_values$Model[ROH_hotspot_threshold_values$Model == "Selection"] <- selection_model_names_list_HO
# Sort the data frame based on the ROH-hotspot threshold
ROH_hotspot_threshold_values_sorted <- ROH_hotspot_threshold_values[order(ROH_hotspot_threshold_values$ROH_hotspot_thr), ]


# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_ROH-hotspot_threshold_comparison",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(ROH_hotspot_threshold_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = ROH_hotspot_threshold_values,
#   sort_column = "ROH_hotspot_thr",  
#   output_dir = output_dir,
#   output_filename = "ROH-hotspot_threshold_comparison"  # File name without extension
# )
# Print the table using knitr::kable()
knitr::kable(ROH_hotspot_threshold_values_sorted, row.names = FALSE)

```
## 1.2 ROH-hotspots - ROH Frequency and Length
```{r ,echo = FALSE,warning = FALSE}
setwd(Empirical_data_ROH_hotspots_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*ROH_Hotspot_windows*.bed$"
empirical_roh_hotspot_bed_files <- list.files(path = Empirical_data_ROH_hotspots_dir, pattern = pattern)

# chromosome_number_pattern <- "^german_shepherd_CHR(\\d+)_.*"
chromosome_number_pattern <- paste0("^",empirical_dog_breed,"_CHR(\\d+)_.*")
# Extract chromosome numbers
chr_numbers <- sub(tolower(chromosome_number_pattern), "\\1", tolower(empirical_roh_hotspot_bed_files))

# Sort the files based on chromosome numbers
empirical_roh_hotspot_bed_files <- empirical_roh_hotspot_bed_files[order(as.numeric(chr_numbers))]


# Create an empty list to store information for the different ROH-hotspots in
empirical_hotspot_tables <- list()

# Loop through each .bed file (ROH-hotspot allele frequency window-file)
for (file in empirical_roh_hotspot_bed_files) {
  # Extract chromosome number and window number from file name
  chromosome <- as.numeric(sub(tolower(chromosome_number_pattern), "\\1", tolower(file)))
  column_names <- c("CHR","POS1","POS2")
  # Read the .bed file into a data frame, skipping commented lines
  chromosome_bed_file_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Loop through each hotspot for the current chromosome
  for (i in 1:nrow(chromosome_bed_file_data)) {
    Hotspot_region_data <- data.frame(CHR = chromosome_bed_file_data[i, ][1],POS1 = chromosome_bed_file_data[i, ][2],POS2 = chromosome_bed_file_data[i, ][3])
    Hotspot_length_bp <- Hotspot_region_data$POS2-Hotspot_region_data$POS1 + 1
    Hotspot_length_Mb <- Hotspot_length_bp / 1e6
    Hotspot_name <- paste("Hotspot_chr",chromosome, "_window_",i, sep = "")
      # Find the row where the variant_position_bp is within POS1 and POS2, and CHR equals chr_number
      roh_freq_windows_in_hotspot <- ROH_freq_table_Empirical_Data[[chromosome]][["data"]][ Hotspot_region_data$POS1 <= ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS1 & ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS2 <= Hotspot_region_data$POS2, ]
    
    avg_frequency <- mean(roh_freq_windows_in_hotspot$FREQUENCY)
    
    # Check if the selection coefficient already exists in the list
    if (!(Hotspot_name %in% names(empirical_hotspot_tables))) {
      # If it doesn't exist, create an empty data frame
      empirical_hotspot_tables[[Hotspot_name]] <- data.frame()
    }
  
     # Create a list with table name and corresponding data frame
    table_info <- list(Filename = file,Hotspot_length_bp=Hotspot_length_bp,Hotspot_length_Mb=Hotspot_length_Mb,Avg_frequency = avg_frequency, Hotspot_region_data = Hotspot_region_data) 
    
    # Append the table info to the list under selection_scenario
    empirical_hotspot_tables[[Hotspot_name]] <- c(empirical_hotspot_tables[[Hotspot_name]], table_info)
        }

}
# View(empirical_hotspot_tables)
```

# 6: Expected Heterozygosity
## 6.1 Empirical data - MAF 0.05
```{r Expected Heterozygosity - Empirical data MAF 0.05, echo = FALSE,warning = FALSE}
setwd(Empirical_data_H_e_dir_MAF_0_05)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
# pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
pattern <- "^.*H_e_distribution_.*.tsv$"
empirical_H_e_distribution_file <- list.files(path = Empirical_data_H_e_dir_MAF_0_05, pattern = pattern)

# Check if exactly one file is found
if (length(empirical_H_e_distribution_file) != 1) {
  stop("There should be exactly one file matching the pattern.")
}

# Read the file
file <- empirical_H_e_distribution_file[1]

# Read the .tsv file into a data frame
empirical_H_e_distribution_table_MAF_0_05 <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

```

## 6.2 HO Neutral Model - MAF 0.05
```{r Expected Heterozygosity - Neutral Model - MAF 0.05, echo = FALSE,warning = FALSE}
setwd(Neutral_model_H_e_dir_MAF_0_05_HO) 
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files_HO <- list.files(pattern = pattern)

# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files_HO) != 1) {
  stop("There should be exactly one file matching the pattern.")
}

# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files_HO[1]

# Read the .tsv file into a data frame
data <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO <- list(results = data)

# Replace NA values with 0
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Fifth_Percentile"]][is.na(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Fifth_Percentile"]])] <- 0

H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Fifth_Percentile"]])
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$Estimated_Avg_Window_based_H_e <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Avg_H_e"]])

# Calculate the  confidence interval of the point estimate Avg H_e across all 20 simulations
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Avg_H_e"]])

# Calculate the  standard deviation across all 20 simulations
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$H_e_Standard_deviation <- standard_deviation_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Avg_H_e"]])

#View(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO)
```
## 6.2 Sams Neutral Model - MAF 0.05
```{r Expected Heterozygosity - Neutral Model - MAF 0.05, echo = FALSE,warning = FALSE}
setwd(Neutral_model_H_e_dir_MAF_0_05_SAMS)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files_SAMS <- list.files(pattern = pattern)

# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files_SAMS) != 1) {
  stop("There should be exactly one file matching the pattern.")
}

# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files_SAMS[1]

# Read the .tsv file into a data frame
data <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS <- list(results = data)

# Replace NA values with 0
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Fifth_Percentile"]][is.na(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Fifth_Percentile"]])] <- 0

H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Fifth_Percentile"]])
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$Estimated_Avg_Window_based_H_e <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Avg_H_e"]])

# Calculate the  confidence interval of the point estimate Avg H_e across all 20 simulations
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Avg_H_e"]])

# Calculate the  standard deviation across all 20 simulations
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$H_e_Standard_deviation <- standard_deviation_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Avg_H_e"]])

#View(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS)
```


## 6.3 HO Selection Model
```{r echo = FALSE,warning = FALSE}
# cat("Uncommented because change of analysis")
# setwd(Selection_model_H_e_dir_HO)
# # Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
# pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
# selection_model_5th_percentiles_of_H_e_files_HO <- list.files(path = Selection_model_H_e_dir_HO, pattern = pattern)
# # selection_model_5th_percentiles_of_H_e_files_HO
# # Initialize an empty list to store H_e_5th_percentiles_Selection_models_HO
# H_e_5th_percentiles_Selection_models_HO <- list()
# # Loop through each selection coefficient and its associated file
# for (i in seq_along(selection_model_5th_percentiles_of_H_e_files_HO)) {
#   # Extract the selection coefficient from the file name
#   selection_coefficient <- sub(".*(selection_model_s\\d+_chr\\d+).*", "\\1", selection_model_5th_percentiles_of_H_e_files_HO[i])
#   # Read the .tsv file into a data frame
#   subtable <- read.table(selection_model_5th_percentiles_of_H_e_files_HO[i], header = TRUE,sep = "\t", stringsAsFactors = FALSE)
#   H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files_HO[i]
#   # Add the subtable to the list with the selection coefficient as its name
#   H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$results <- subtable
# }
# # # View the H_e_5th_percentiles_Selection_models_HO
# # H_e_5th_percentiles_Selection_models_HO
# # Calculating Average F_ROH for each table
# # Loop through each selection_coefficient
# for (selection_coefficient in names(H_e_5th_percentiles_Selection_models_HO)) {
#   # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
#   H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
#   # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
#   # Store the bootstrap confidence interval in the H_e_5th_percentiles_Selection_models_HO table
#   H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
# }
# # # View the dataframe
# # View(H_e_5th_percentiles_Selection_models_HO)

```
## 6.3 Sams Selection Model
```{r echo = FALSE,warning = FALSE}
# cat("Uncommented because change of analysis")
# setwd(Selection_model_H_e_dir_SAMS)
# # Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
# pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
# selection_model_5th_percentiles_of_H_e_files_SAMS <- list.files(path = Selection_model_H_e_dir_SAMS, pattern = pattern)
# # selection_model_5th_percentiles_of_H_e_files_SAMS
# # Initialize an empty list to store H_e_5th_percentiles_Selection_models_SAMS
# H_e_5th_percentiles_Selection_models_SAMS <- list()
# # Loop through each selection coefficient and its associated file
# for (i in seq_along(selection_model_5th_percentiles_of_H_e_files_SAMS)) {
#   # Extract the selection coefficient from the file name
#   selection_coefficient <- sub(".*(selection_model_s\\d+_chr\\d+).*", "\\1", selection_model_5th_percentiles_of_H_e_files_SAMS[i])
#   # Read the .tsv file into a data frame
#   subtable <- read.table(selection_model_5th_percentiles_of_H_e_files_SAMS[i], header = TRUE,sep = "\t", stringsAsFactors = FALSE)
#   H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files_SAMS[i]
#   # Add the subtable to the list with the selection coefficient as its name
#   H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$results <- subtable
# }
# # # View the H_e_5th_percentiles_Selection_models_SAMS
# # H_e_5th_percentiles_Selection_models_SAMS
# # Calculating Average F_ROH for each table
# # Loop through each selection_coefficient
# for (selection_coefficient in names(H_e_5th_percentiles_Selection_models_SAMS)) {
#   # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
#   H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
#   # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
#   # Store the bootstrap confidence interval in the H_e_5th_percentiles_Selection_models_SAMS table
#   H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
# }
# # # View the dataframe
# # View(H_e_5th_percentiles_Selection_models_SAMS)

```

## 6.4 Genomewide Average H_e
```{r Expected Heterozygosity Avg H_e Summary, echo = FALSE,warning = FALSE}
# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["results"]][["Avg_H_e"]])

neutral_avg_H_e_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$Estimated_Mean_Population_H_e 
neutral_lower_ci_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$SE_CI_Estimated_Mean_H_e[2]
neutral_standard_deviation_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["H_e_Standard_deviation"]]
neutral_HO_Coefficient_of_Variation <- 100*(neutral_standard_deviation_HO/neutral_avg_H_e_HO)

# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["results"]][["Avg_H_e"]])

neutral_avg_H_e_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$Estimated_Mean_Population_H_e 
neutral_lower_ci_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$SE_CI_Estimated_Mean_H_e[2]
neutral_standard_deviation_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["H_e_Standard_deviation"]]
neutral_SAMS_Coefficient_of_Variation <- 100*(neutral_standard_deviation_SAMS/neutral_avg_H_e_SAMS)

# Extract empirical model value
empirical_avg_H_e <- empirical_H_e_distribution_table_MAF_0_05$Avg_H_e
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
empirical_standard_deviation <- NA # Placeholder value
empirical_Coefficient_of_Variation <- NA # Placeholder value

neutral_model_H_e_error_perc_HO <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO$Estimated_Mean_Population_H_e/empirical_H_e_distribution_table_MAF_0_05$Avg_H_e)))
                                     ,H_e_values_decimals)

neutral_model_H_e_error_perc_SAMS <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS$Estimated_Mean_Population_H_e/empirical_H_e_distribution_table_MAF_0_05$Avg_H_e)))
                                     ,H_e_values_decimals)
empirical_H_e_error_perc <- NA # Placeholder 


# Combine all values into a data frame
H_e_values_MAF_0_05 <- data.frame(
  Model = c("Neutral - Sams ","Neutral - HO", "Empirical"),
  H_e = c(neutral_avg_H_e_SAMS, neutral_avg_H_e_HO, empirical_avg_H_e),
  Lower_CI = c(neutral_lower_ci_SAMS, neutral_lower_ci_HO, empirical_lower_ci),
  Upper_CI = c(neutral_upper_ci_SAMS, neutral_upper_ci_HO, empirical_upper_ci),
  Standard_Deviation = c(neutral_standard_deviation_SAMS ,neutral_standard_deviation_HO,empirical_standard_deviation),
  Coefficient_of_variation = c(neutral_SAMS_Coefficient_of_Variation,neutral_HO_Coefficient_of_Variation,empirical_Coefficient_of_Variation),
  Error_percentage = c(neutral_model_H_e_error_perc_SAMS,neutral_model_H_e_error_perc_HO,empirical_H_e_error_perc)
)

# Format all numeric values to 5 decimal places
H_e_values_MAF_0_05$H_e <- round(H_e_values_MAF_0_05$H_e, H_e_values_decimals)
H_e_values_MAF_0_05$Lower_CI <- round(H_e_values_MAF_0_05$Lower_CI,H_e_values_decimals)
H_e_values_MAF_0_05$Upper_CI <- round(H_e_values_MAF_0_05$Upper_CI,H_e_values_decimals)
H_e_values_MAF_0_05$Error_percentage <- round(H_e_values_MAF_0_05$Error_percentage,Error_percentage_decimals)
H_e_values_MAF_0_05$Standard_Deviation <- round(H_e_values_MAF_0_05$Standard_Deviation,Standard_deviation_decimals)
H_e_values_MAF_0_05$Coefficient_of_variation <- round(H_e_values_MAF_0_05$Coefficient_of_variation,Error_percentage_decimals)

H_e_values_MAF_0_05$H_e <- as.numeric(round(H_e_values_MAF_0_05$H_e,H_e_values_decimals))
# Sort the data frame based on H_e column
H_e_values_MAF_0_05_sorted <- H_e_values_MAF_0_05[order(as.numeric(H_e_values_MAF_0_05$H_e)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_MAF_0_05_Genomic_Average_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_values_MAF_0_05_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_values_MAF_0_05,
#   sort_column = "H_e",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )
# Print the table using knitr::kable()
knitr::kable(H_e_values_MAF_0_05_sorted, row.names = FALSE)

```



## 6.5 Genomewide 5th percentile comparison - Expected Heterozygosity Summary

```{r Expected Heterozygosity 5th percentile Summary, echo = FALSE,warning = FALSE}
# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci_HO <- H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]

# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci_SAMS <- H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]

# Extract empirical model value
empirical_avg_H_e_5th_percentile <- empirical_H_e_distribution_table_MAF_0_05$Fifth_Percentile
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound

# Extract neutral model values and CI bounds

neutral_model_H_e_5th_percentiles_error_perc_HO <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_MAF_0_05_HO[["Estimated_Mean_H_e_5th_percentile"]]/empirical_H_e_distribution_table_MAF_0_05$Fifth_Percentile)))
                                     ,H_e_values_decimals)

neutral_model_H_e_5th_percentiles_error_perc_SAMS <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_MAF_0_05_SAMS[["Estimated_Mean_H_e_5th_percentile"]]/empirical_H_e_distribution_table_MAF_0_05$Fifth_Percentile)))
                                     ,H_e_values_decimals)

empirical_H_e_5th_percentiles_error_perc_SAMS <- NA # Placeholder

# Combine all values into a data frame
H_e_5th_percentile_values_MAF_0_05 <- data.frame(
  Model = c("Neutral - Sams", "Neutral - HO", "Empirical"),
  H_e_5th_percentile = c(neutral_avg_H_e_5th_percentile_SAMS, neutral_avg_H_e_5th_percentile_HO, empirical_avg_H_e_5th_percentile),
  Lower_CI = c(neutral_lower_ci_SAMS, neutral_lower_ci_HO, empirical_lower_ci),
  Upper_CI = c(neutral_upper_ci_SAMS, neutral_upper_ci_HO, empirical_upper_ci),
  Error_perc = c(neutral_model_H_e_5th_percentiles_error_perc_SAMS,neutral_model_H_e_5th_percentiles_error_perc_HO,empirical_H_e_5th_percentiles_error_perc_SAMS)
)

# Format all numeric values to 5 decimal places
H_e_5th_percentile_values_MAF_0_05$H_e_5th_percentile <- round(H_e_5th_percentile_values_MAF_0_05$H_e_5th_percentile, H_e_values_decimals)
H_e_5th_percentile_values_MAF_0_05$Lower_CI <- round(H_e_5th_percentile_values_MAF_0_05$Lower_CI,H_e_values_decimals)
H_e_5th_percentile_values_MAF_0_05$Upper_CI <- round(H_e_5th_percentile_values_MAF_0_05$Upper_CI,H_e_values_decimals)
H_e_5th_percentile_values_MAF_0_05$Error_perc <- round(H_e_5th_percentile_values_MAF_0_05$Error_perc,Error_percentage_decimals)
# # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
# # formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_model_names)
# formatted_selection_coefficient_labels <-sub("s(\\d)(\\d+)_.*", "s=\\1.\\2", selection_model_names)
# H_e_5th_percentile_values_MAF_0_05$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels
H_e_5th_percentile_values_MAF_0_05$H_e_5th_percentile <- as.numeric(round(H_e_5th_percentile_values_MAF_0_05$H_e_5th_percentile,H_e_values_decimals))

# Sort the data frame based on H_e_5th_percentile column
H_e_5th_percentile_values_MAF_0_05_sorted <- H_e_5th_percentile_values_MAF_0_05[order(as.numeric(H_e_5th_percentile_values_MAF_0_05$H_e_5th_percentile)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_MAF_0_05_5th_percentile_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_5th_percentile_values_MAF_0_05_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_5th_percentile_values_MAF_0_05,
#   sort_column = "H_e_5th_percentile",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )

# Print the table using knitr::kable()
knitr::kable(H_e_5th_percentile_values_MAF_0_05_sorted, row.names = FALSE)

```








# 2: Inbreeding coefficient

## 2.1 Empirical data

```{r echo = FALSE,warning = FALSE}
# Set the working directory to the directory containing the F_ROH files for the empirical data
setwd(Empirical_data_F_ROH_dir)

# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
population_F_ROH_file <- list.files(path = Empirical_data_F_ROH_dir, pattern = pattern)

# Extract the population name from the file names
empirical_population_name <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(population_F_ROH_file))

# Combine population name, number, and file name
population_info <- data.frame(empirical_population_name = empirical_population_name, file_name = population_F_ROH_file)
population_info <- population_info[order(population_info$file_name), ]

# Initialize an empty list to store the data
F_ROH_table_Empirical_Data <- list()

# Loop through each .tsv file
for (i in 1:length(population_info$empirical_population_name)) {

  # Get the file name
  file <- population_info$file_name[i]

  # Read the header line
  con <- file(file, "r")
  header <- readLines(con, n = 1)
  close(con)

  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]

  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)

  # Add empirical_population_name as an attribute to the data frame
  attr(F_ROH_data, "empirical_population_name") <- population_info$empirical_population_name[i]

  # Add filename as an attribute to the data frame
  attr(F_ROH_data, "filename") <- file_name

  # Calculate the mean of the "F_ROH" column
  avg_F_ROH_population <- mean(F_ROH_data$F_ROH)
  
  # Create a list with table name and corresponding data frame
  table_info <- list(empirical_population_name = population_info$empirical_population_name[i], filename = file, data = F_ROH_data,Avg_F_ROH = avg_F_ROH_population )  # Added empirical_population_name here

  # Append the table info to the list
  F_ROH_table_Empirical_Data <- c(F_ROH_table_Empirical_Data, table_info)
}

# Creating a histogram showing the spread in F_ROH values across the empirical population 

histogram_title <- paste0("F_ROH distribution for ",empirical_population_name)
hist(F_ROH_data$F_ROH, main = histogram_title, xlab = "F_ROH", ylab = "Frequency", col = "skyblue")


empirical_avg_F_ROH_legend_text <- paste(empirical_population_name," Average: ", round(F_ROH_table_Empirical_Data[["Avg_F_ROH"]], 3))

# Add a vertical line for the average F_ROH of the empirical population
abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
# Add legend
legend("topright", legend = empirical_avg_F_ROH_legend_text,
       col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black")


# Print the overall average Avg_F_ROH
cat("Overall Average Avg_F_ROH for ",empirical_population_name,":",F_ROH_table_Empirical_Data[["Avg_F_ROH"]], "//n")


# View the modified data structure
#View(F_ROH_table_Empirical_Data)

```

## 2.2 HO Neutral Model

```{r echo = FALSE,warning = FALSE}
# Set the working directory to the directory containing the F_ROH files for the empirical data
setwd(Neutral_model_F_ROH_dir_HO)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files_HO <- list.files(path = Neutral_model_F_ROH_dir_HO, pattern = pattern)
# Extract the simulation name from the file names
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "////1", tolower(simulation_F_ROH_files_HO))
# Extract the simulation number after "sim_"
simulation_numbers <- as.integer(sub(tolower("^sim_(////d+)_.*"), "////1", tolower(simulation_F_ROH_files_HO)))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files_HO)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Neutral_Model_HO <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract the table name from the file name
  file_name <- gsub("////.tsv$", "", file)
  # Read the header line
  con <- file(file, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  # Added sim_name here
  # Append the table info to the list
  F_ROH_tables_Neutral_Model_HO <- c(F_ROH_tables_Neutral_Model_HO, list(table_info))
}
# Calculating Population F_ROH for each simulation (subtable)
# Loop through each table in F_ROH_tables_Neutral_Model_HO
for (i in seq_along(F_ROH_tables_Neutral_Model_HO)) {
  # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
  F_ROH_tables_Neutral_Model_HO[[i]]$Population_F_ROH <- mean(F_ROH_tables_Neutral_Model_HO[[i]]$data$F_ROH)
}
#View(F_ROH_tables_Neutral_Model_HO)
# Extract all population F_ROH values from F_ROH_tables_Neutral_Model_HO
All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Neutral_Model_HO, function(table) table$Population_F_ROH))
# Remove any non-numeric values
All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
# Calculate the point estimate F_ROH across all 20 simulations
F_ROH_tables_Neutral_Model_HO$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)

# Calculate the standard error confidence interval of the point estimate F_ROH across all 20 simulations
F_ROH_tables_Neutral_Model_HO$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
F_ROH_tables_Neutral_Model_HO$Standard_deviation <- standard_deviation_fun(All_Population_F_ROH)

# Set the plot size
options(repr.plot.width = 10, repr.plot.height = 6)
# Create histogram for simulated data
hist(All_Population_F_ROH, main = "HO: Population F_ROH for the Neutral Model simulations", xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
# Determine the location of the legend based on the comparison
if (F_ROH_tables_Neutral_Model_HO$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
  simulated_line_location <- "topright"
  empirical_line_location <- "topleft"
} else {
  simulated_line_location <- "topleft"
  empirical_line_location <- "topright"
}
# Add a red vertical line for the point estimate F_ROH across all 20 simulations
abline(v = F_ROH_tables_Neutral_Model_HO$Estimated_Mean_Population_F_ROH, col = neutral_model_color, lwd = histogram_line_sizes)
# Add legend for the red line
legend(simulated_line_location, legend = paste("Neutral - F_ROH Point estimate: ", round(F_ROH_tables_Neutral_Model_HO$Estimated_Mean_Population_F_ROH, 4)),
       col = neutral_model_color, lty = 1, cex = 0.8, text.col = "black")
# Add a blue vertical line for the average F_ROH of the empirical population
abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
# Add legend for the green line
legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
       col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
# Reset par settings to default after plotting
par(mfrow = c(1, 1))
# Print the Point estimate of F_ROH across all 20 simulations
cat("Point estimate F_ROH across all 20 simulations:", F_ROH_tables_Neutral_Model_HO$Estimated_Mean_Population_F_ROH, "//n")
print(paste("Bootstrap 95% Confidence Interval: [", 
            F_ROH_tables_Neutral_Model_HO$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
            F_ROH_tables_Neutral_Model_HO$SE_CI_Estimated_Mean_Population_F_ROH[2], "]", sep = ""))
```
## 2.2 SAMS Neutral Model
```{r echo = FALSE,warning = FALSE}
# Set the working directory to the directory containing the F_ROH files for the empirical data
setwd(Neutral_model_F_ROH_dir_SAMS)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files_SAMS <- list.files(path = Neutral_model_F_ROH_dir_SAMS, pattern = pattern)
# Extract the simulation name from the file names
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "////1", tolower(simulation_F_ROH_files_SAMS))
# Extract the simulation number after "sim_"
simulation_numbers <- as.integer(sub(tolower("^sim_(////d+)_.*"), "////1", tolower(simulation_F_ROH_files_SAMS)))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files_SAMS)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Neutral_Model_SAMS <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract the table name from the file name
  file_name <- gsub("////.tsv$", "", file)
  # Read the header line
  con <- file(file, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  # Added sim_name here
  # Append the table info to the list
  F_ROH_tables_Neutral_Model_SAMS <- c(F_ROH_tables_Neutral_Model_SAMS, list(table_info))
}
# Calculating Population F_ROH for each simulation (subtable)
# Loop through each table in F_ROH_tables_Neutral_Model_SAMS
for (i in seq_along(F_ROH_tables_Neutral_Model_SAMS)) {
  # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
  F_ROH_tables_Neutral_Model_SAMS[[i]]$Population_F_ROH <- mean(F_ROH_tables_Neutral_Model_SAMS[[i]]$data$F_ROH)
}
#View(F_ROH_tables_Neutral_Model_SAMS)
# Extract all population F_ROH values from F_ROH_tables_Neutral_Model_SAMS
All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Neutral_Model_SAMS, function(table) table$Population_F_ROH))
# Remove any non-numeric values
All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
# Calculate the point estimate F_ROH across all 20 simulations
F_ROH_tables_Neutral_Model_SAMS$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)

# Calculate the standard error confidence interval of the point estimate F_ROH across all 20 simulations
F_ROH_tables_Neutral_Model_SAMS$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
F_ROH_tables_Neutral_Model_SAMS$Standard_deviation <- standard_deviation_fun(All_Population_F_ROH)

# Set the plot size
options(repr.plot.width = 10, repr.plot.height = 6)
# Create histogram for simulated data
hist(All_Population_F_ROH, main = "SAMS: Population F_ROH for the Neutral Model simulations", xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
# Determine the location of the legend based on the comparison
if (F_ROH_tables_Neutral_Model_SAMS$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
  simulated_line_location <- "topright"
  empirical_line_location <- "topleft"
} else {
  simulated_line_location <- "topleft"
  empirical_line_location <- "topright"
}
# Add a red vertical line for the point estimate F_ROH across all 20 simulations
abline(v = F_ROH_tables_Neutral_Model_SAMS$Estimated_Mean_Population_F_ROH, col = neutral_model_color, lwd = histogram_line_sizes)
# Add legend for the red line
legend(simulated_line_location, legend = paste("Neutral - F_ROH Point estimate: ", round(F_ROH_tables_Neutral_Model_SAMS$Estimated_Mean_Population_F_ROH, 4)),
       col = neutral_model_color, lty = 1, cex = 0.8, text.col = "black")
# Add a blue vertical line for the average F_ROH of the empirical population
abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
# Add legend for the green line
legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
       col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
# Reset par settings to default after plotting
par(mfrow = c(1, 1))
# Print the Point estimate of F_ROH across all 20 simulations
cat("Point estimate F_ROH across all 20 simulations:", F_ROH_tables_Neutral_Model_SAMS$Estimated_Mean_Population_F_ROH, "//n")
print(paste("Bootstrap 95% Confidence Interval: [", 
            F_ROH_tables_Neutral_Model_SAMS$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
            F_ROH_tables_Neutral_Model_SAMS$SE_CI_Estimated_Mean_Population_F_ROH[2], "]", sep = ""))
```



## 2.3 HO Selection Model
```{r echo = FALSE,warning = FALSE}
# Set the working directory to the directory containing the F_ROH files for the empirical data
setwd(Selection_model_F_ROH_dir_HO)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files_HO <- list.files(path = Selection_model_F_ROH_dir_HO, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
simulation_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(simulation_F_ROH_files_HO)))
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(simulation_F_ROH_files_HO))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files_HO)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Selection_Model_HO <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract the selection_model_type from the file name
  selection_model_type <- sub(tolower("^sim_[0-9]+_(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the selection_model_type already exists in the list
  if (!(selection_model_type %in% names(F_ROH_tables_Selection_Model_HO))) {
    # If it doesn't exist, create a list for it
    F_ROH_tables_Selection_Model_HO[[selection_model_type]] <- list()
  }
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Read the header line
  con <- file(file, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Assign the file name to file_name
  file_name <- sub("\\.tsv$", "", sim_info$file_name[i])
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  # Fixed filename assignment
  # Append the table info to the list under selection_model_type
  F_ROH_tables_Selection_Model_HO[[selection_model_type]] <- c(F_ROH_tables_Selection_Model_HO[[selection_model_type]], list(table_info))
}
# Calculating Average F_ROH for each table
# Loop through each selection_coefficient
for (selection_coefficient in names(F_ROH_tables_Selection_Model_HO)) {
  # Loop through each table in the selection_coefficient
  for (i in seq_along(F_ROH_tables_Selection_Model_HO[[selection_coefficient]])) {
    # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
    # of the current selection coefficient
    F_ROH_tables_Selection_Model_HO[[selection_coefficient]][[i]]$Population_F_ROH <- mean(F_ROH_tables_Selection_Model_HO[[selection_coefficient]][[i]]$data$F_ROH)
  }
  # Extract all pop_Avg_F_ROH values from F_ROH_tables_Selection_Model_HO
  All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Selection_Model_HO[[selection_coefficient]], function(table) table$Population_F_ROH))
  # Remove any non-numeric values
  All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
  # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
  F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)
  # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
  # Store the bootstrap confidence interval in the F_ROH_tables_Selection_Model_HO table
  F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
  # Set the plot size
  options(repr.plot.width = 10, repr.plot.height = 6)
  # Creating a histogram showing the spread in average F_ROH values across each technical replicate 
  # for the current selection coefficient!
  histogram_title <- paste0("Population F_ROH for ",selection_coefficient)
  hist(All_Population_F_ROH, main = histogram_title, xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
  # Determine the location of the legend based on the comparison
  if (F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
    simulated_line_location <- "topright"
    empirical_line_location <- "topleft"
  } else {
    simulated_line_location <- "topleft"
    empirical_line_location <- "topright"
  }
  # Add a vertical line for the overall average Avg_F_ROH of the current selection model
  abline(v = F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, col = selection_model_color, lwd = histogram_line_sizes)
  # Add legend for the red line
  legend(simulated_line_location, legend = paste("Selection Coefficient F_ROH Point estimate:", round(F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, F_ROH_values_decimals)),
       col = selection_model_color, lty = 1, cex = 0.8, text.col = "black")
  # Add a vertical line for the average F_ROH of the empirical population
  abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
  # Add legend for the empirical line
  legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
         col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
  # Reset par settings to default after plotting
  par(mfrow = c(1, 1))
  # Print the Point estimate of F_ROH across all 20 simulations
  cat("Point estimate F_ROH across all 20 simulations for ",selection_coefficient,":", F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, "//n")
  print(paste("Bootstrap 95% Confidence Interval: [", 
  F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
  F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[2], "]", sep = ""))
}

#View(F_ROH_tables_Selection_Model_HO)
```
## 2.3 SAMS Selection Model
```{r echo = FALSE,warning = FALSE}
# Set the working directory to the directory containing the F_ROH files for the empirical data
setwd(Selection_model_F_ROH_dir_SAMS)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files_SAMS <- list.files(path = Selection_model_F_ROH_dir_SAMS, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
simulation_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(simulation_F_ROH_files_SAMS)))
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(simulation_F_ROH_files_SAMS))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files_SAMS)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Selection_Model_SAMS <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  # Extract the selection_model_type from the file name
  selection_model_type <- sub(tolower("^sim_[0-9]+_(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the selection_model_type already exists in the list
  if (!(selection_model_type %in% names(F_ROH_tables_Selection_Model_SAMS))) {
    # If it doesn't exist, create a list for it
    F_ROH_tables_Selection_Model_SAMS[[selection_model_type]] <- list()
  }
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Read the header line
  con <- file(file, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Assign the file name to file_name
  file_name <- sub("\\.tsv$", "", sim_info$file_name[i])
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  # Fixed filename assignment
  # Append the table info to the list under selection_model_type
  F_ROH_tables_Selection_Model_SAMS[[selection_model_type]] <- c(F_ROH_tables_Selection_Model_SAMS[[selection_model_type]], list(table_info))
}
# Calculating Average F_ROH for each table
# Loop through each selection_coefficient
for (selection_coefficient in names(F_ROH_tables_Selection_Model_SAMS)) {
  # Loop through each table in the selection_coefficient
  for (i in seq_along(F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]])) {
    # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
    # of the current selection coefficient
    F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]][[i]]$Population_F_ROH <- mean(F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]][[i]]$data$F_ROH)
  }
  # Extract all pop_Avg_F_ROH values from F_ROH_tables_Selection_Model_SAMS
  All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]], function(table) table$Population_F_ROH))
  # Remove any non-numeric values
  All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
  # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
  F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)
  # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
  # Store the bootstrap confidence interval in the F_ROH_tables_Selection_Model_SAMS table
  F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
  # Set the plot size
  options(repr.plot.width = 10, repr.plot.height = 6)
  # Creating a histogram showing the spread in average F_ROH values across each technical replicate 
  # for the current selection coefficient!
  histogram_title <- paste0("Population F_ROH for ",selection_coefficient)
  hist(All_Population_F_ROH, main = histogram_title, xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
  # Determine the location of the legend based on the comparison
  if (F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
    simulated_line_location <- "topright"
    empirical_line_location <- "topleft"
  } else {
    simulated_line_location <- "topleft"
    empirical_line_location <- "topright"
  }
  # Add a vertical line for the overall average Avg_F_ROH of the current selection model
  abline(v = F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, col = selection_model_color, lwd = histogram_line_sizes)
  # Add legend for the red line
  legend(simulated_line_location, legend = paste("Selection Coefficient F_ROH Point estimate:", round(F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, F_ROH_values_decimals)),
       col = selection_model_color, lty = 1, cex = 0.8, text.col = "black")
  # Add a vertical line for the average F_ROH of the empirical population
  abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
  # Add legend for the empirical line
  legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
         col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
  # Reset par settings to default after plotting
  par(mfrow = c(1, 1))
  # Print the Point estimate of F_ROH across all 20 simulations
  cat("Point estimate F_ROH across all 20 simulations for ",selection_coefficient,":", F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, "//n")
  print(paste("Bootstrap 95% Confidence Interval: [", 
  F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
  F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[2], "]", sep = ""))
}

#View(F_ROH_tables_Selection_Model_SAMS)

```
## 2.4 F_ROH summary
```{r echo = FALSE,warning = FALSE}

# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_HO <- c()
# selection_model_lower_ci_HO <- c()
# selection_model_upper_ci_HO <- c()
# selection_model_names_HO <- c()
# 
# # Loop through each selection_coefficient in F_ROH_tables_Selection_Model_HO
# for (selection_coefficient in names(F_ROH_tables_Selection_Model_HO)) {
#   # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
#   formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_coefficient)
# 
#   
#   # Extract the all_avg_F_ROH value from the selection_coefficient
#   all_avg_F_ROH <- F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$Estimated_Mean_Population_F_ROH
#   CI <- F_ROH_tables_Selection_Model_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH
#   
#   # Append values to the lists
#   selection_model_names_HO <- c(selection_model_names_HO,formatted_selection_coefficient_labels)
#   selection_model_avg_values_HO <- c(selection_model_avg_values_HO, all_avg_F_ROH)
#   selection_model_lower_ci_HO <- c(selection_model_lower_ci_HO, CI[1])
#   selection_model_upper_ci_HO <- c(selection_model_upper_ci_HO, CI[2])
# }
# 
# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_SAMS <- c()
# selection_model_lower_ci_SAMS <- c()
# selection_model_upper_ci_SAMS <- c()
# selection_model_names_SAMS <- c()
# 
# # Loop through each selection_coefficient in F_ROH_tables_Selection_Model_SAMS
# for (selection_coefficient in names(F_ROH_tables_Selection_Model_SAMS)) {
#   # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
#   formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_coefficient)
# 
#   
#   # Extract the all_avg_F_ROH value from the selection_coefficient
#   all_avg_F_ROH <- F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$Estimated_Mean_Population_F_ROH
#   CI <- F_ROH_tables_Selection_Model_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH
#   
#   # Append values to the lists
#   selection_model_names_SAMS <- c(selection_model_names_SAMS,formatted_selection_coefficient_labels)
#   selection_model_avg_values_SAMS <- c(selection_model_avg_values_SAMS, all_avg_F_ROH)
#   selection_model_lower_ci_SAMS <- c(selection_model_lower_ci_SAMS, CI[1])
#   selection_model_upper_ci_SAMS <- c(selection_model_upper_ci_SAMS, CI[2])
# }
# 


# Extract neutral model values and CI bounds
neutral_avg_F_ROH_HO <- F_ROH_tables_Neutral_Model_HO[["Estimated_Mean_Population_F_ROH"]]
neutral_lower_ci_HO <- F_ROH_tables_Neutral_Model_HO[["SE_CI_Estimated_Mean_Population_F_ROH"]][1]
neutral_upper_ci_HO <- F_ROH_tables_Neutral_Model_HO[["SE_CI_Estimated_Mean_Population_F_ROH"]][2]
neutral_HO_standard_deviation <- F_ROH_tables_Neutral_Model_HO[["Standard_deviation"]]
neutral_HO_Coefficient_of_Variation <- 100*(neutral_HO_standard_deviation/neutral_avg_F_ROH_HO)

# Extract neutral model values and CI bounds
neutral_avg_F_ROH_SAMS <- F_ROH_tables_Neutral_Model_SAMS[["Estimated_Mean_Population_F_ROH"]]
neutral_lower_ci_SAMS <- F_ROH_tables_Neutral_Model_SAMS[["SE_CI_Estimated_Mean_Population_F_ROH"]][1]
neutral_upper_ci_SAMS <- F_ROH_tables_Neutral_Model_SAMS[["SE_CI_Estimated_Mean_Population_F_ROH"]][2]
neutral_SAMS_standard_deviation <- F_ROH_tables_Neutral_Model_SAMS[["Standard_deviation"]]
neutral_SAMS_Coefficient_of_Variation <- 100*(neutral_SAMS_standard_deviation/neutral_avg_F_ROH_SAMS)

# Extract empirical model value
empirical_avg_F_ROH <- F_ROH_table_Empirical_Data[["Avg_F_ROH"]]
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
empirical_standard_deviation <- NA # Placeholder value
empirical_Coefficient_of_Variation <- NA # Placeholder value

neutral_model_F_ROH_error_perc_HO <- round(100*( abs( 1-(F_ROH_tables_Neutral_Model_HO[["Estimated_Mean_Population_F_ROH"]]/F_ROH_table_Empirical_Data[["Avg_F_ROH"]])))
                                     ,ROH_frequency_decimals)

neutral_model_F_ROH_error_perc_SAMS <- round(100*( abs( 1-(F_ROH_tables_Neutral_Model_SAMS[["Estimated_Mean_Population_F_ROH"]]/F_ROH_table_Empirical_Data[["Avg_F_ROH"]])))
                                     ,ROH_frequency_decimals)

# Add overAvg_ROH_hotspot_threshold from ROH_freq_tables_Neutral_Model_SAMS
neutral_model_value_SAMS <- round(100*ROH_freq_tables_Neutral_Model_SAMS[["Avg_ROH_hotspot_threshold"]],ROH_frequency_decimals)
# Add Avg_ROH_hotspot_threshold from ROH_freq_table_Empirical_Data
empirical_model_value <- round(100*ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]],ROH_frequency_decimals)
empirical_F_ROH_error_perc <- NA # Placeholder for confidence interval upper bound




# # Combine all values into a data frame
# F_ROH_values <- data.frame(
#   Model = c(rep("Selection", length(selection_model_avg_values_HO)), "Neutral", "Empirical"),
#   F_ROH = c(selection_model_avg_values_HO, neutral_avg_F_ROH_HO, empirical_avg_F_ROH),
#   Lower_CI = c(selection_model_lower_ci_HO, neutral_lower_ci_HO, empirical_lower_ci),
#   Upper_CI = c(selection_model_upper_ci_HO, neutral_upper_ci_HO, empirical_upper_ci)
# )

# Combine all values into a data frame
F_ROH_values <- data.frame(
  Model = c("Neutral - Sams","Neutral - HO", "Empirical"),
  F_ROH = c(neutral_avg_F_ROH_SAMS, neutral_avg_F_ROH_HO, empirical_avg_F_ROH),
  Lower_CI = c(neutral_lower_ci_SAMS, neutral_lower_ci_HO, empirical_lower_ci),
  Upper_CI = c(neutral_upper_ci_SAMS, neutral_upper_ci_HO, empirical_upper_ci),
  Standard_Deviation = c(neutral_SAMS_standard_deviation,neutral_HO_standard_deviation,empirical_standard_deviation),
  Coefficient_of_variation = c(neutral_SAMS_Coefficient_of_Variation,neutral_HO_Coefficient_of_Variation,empirical_Coefficient_of_Variation),
  Error_percentage = c(neutral_model_F_ROH_error_perc_SAMS,neutral_model_F_ROH_error_perc_HO,empirical_F_ROH_error_perc)
)



# Format all numeric values to have the number of decimals defined by F_ROH_values_decimals
F_ROH_values$F_ROH <- round(F_ROH_values$F_ROH,F_ROH_values_decimals)
F_ROH_values$Lower_CI <- as.numeric(round(F_ROH_values$Lower_CI,F_ROH_values_decimals))
F_ROH_values$Upper_CI <- as.numeric(round(F_ROH_values$Upper_CI,F_ROH_values_decimals))
F_ROH_values$Error_percentage <- as.numeric(round(F_ROH_values$Error_percentage,Error_percentage_decimals))
F_ROH_values$Standard_Deviation <- as.numeric(round(F_ROH_values$Standard_Deviation,Standard_deviation_decimals))
F_ROH_values$Coefficient_of_variation <- as.numeric(round(F_ROH_values$Coefficient_of_variation,Error_percentage_decimals))

# # Update the Model column for selection models
# F_ROH_values$Model[1:length(selection_model_names_HO)] <- selection_model_names_HO

# # Extract labels for the different selection coefficients
# selection_labels <- gsub(".*_(s\\d+)_.*", "\\1", selection_model_names_HO)
# F_ROH_values$Model[1:length(selection_model_names_HO)] <- selection_labels

# Sort the data frame based on F_ROH column
F_ROH_values_sorted <- F_ROH_values[order(as.numeric(F_ROH_values$F_ROH)), ]

# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_F_ROH_comparison",".csv", sep = ""))

# Write data to CSV file without quotes
write.table(F_ROH_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = F_ROH_values,
#   sort_column = "F_ROH",  # Sorting was done using this column
#   output_dir = output_dir,
#   output_filename = "F_ROH_comparison"  # File name without extension
# )

# Print the table using knitr::kable()
knitr::kable(F_ROH_values_sorted, row.names = FALSE)

```
# 3: Expected Heterozygosity
## 3.1 Empirical data
```{r Expected Heterozygosity - Empirical data, echo = FALSE,warning = FALSE}
setwd(Empirical_data_H_e_dir_NO_MAF)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
# pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
pattern <- "^.*H_e_distribution_.*.tsv$"
empirical_H_e_distribution_file <- list.files(path = Empirical_data_H_e_dir_NO_MAF, pattern = pattern)
# Check if exactly one file is found
if (length(empirical_H_e_distribution_file) != 1) {
  stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- empirical_H_e_distribution_file[1]
# Read the .tsv file into a data frame
empirical_H_e_distribution_table <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# View(empirical_H_e_distribution_table)
```

## 3.2 HO Neutral Model
```{r HO Expected Heterozygosity - Neutral Model, echo = FALSE,warning = FALSE }
setwd(Neutral_model_H_e_dir_HO)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files_HO <- list.files(path = Neutral_model_H_e_dir_HO, pattern = pattern)
# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files_HO) != 1) {
  stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files_HO[1]
# Read the .tsv file into a data frame
data <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model_HO <- list(results = data)
H_e_5th_percentiles_Neutral_model_HO$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model_HO[["results"]][["Fifth_Percentile"]])
# Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations
# Store the bootstrap confidence interval in the F_ROH_tables_Neutral_Model
H_e_5th_percentiles_Neutral_model_HO$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_HO[["results"]][["Fifth_Percentile"]])
#View(H_e_5th_percentiles_Neutral_model_HO)
```
## 3.2 Sams Neutral Model
```{r HO Expected Heterozygosity - Neutral Model, echo = FALSE,warning = FALSE }
setwd(Neutral_model_H_e_dir_SAMS)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files_SAMS <- list.files(path = Neutral_model_H_e_dir_SAMS, pattern = pattern)
# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files_SAMS) != 1) {
  stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files_SAMS[1]
# Read the .tsv file into a data frame
data <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model_SAMS <- list(results = data)
H_e_5th_percentiles_Neutral_model_SAMS$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model_SAMS[["results"]][["Fifth_Percentile"]])
# Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations
# Store the bootstrap confidence interval in the F_ROH_tables_Neutral_Model
H_e_5th_percentiles_Neutral_model_SAMS$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_SAMS[["results"]][["Fifth_Percentile"]])
#View(H_e_5th_percentiles_Neutral_model_SAMS)

```


## 3.3 HO Selection Model
```{r echo = FALSE,warning = FALSE}
cat("Uncommented because change of analysis")
setwd(Selection_model_H_e_dir_HO)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
selection_model_5th_percentiles_of_H_e_files_HO <- list.files(path = Selection_model_H_e_dir_HO, pattern = pattern)
# selection_model_5th_percentiles_of_H_e_files_HO
# Initialize an empty list to store H_e_5th_percentiles_Selection_models_HO
H_e_5th_percentiles_Selection_models_HO <- list()
# Loop through each selection coefficient and its associated file
for (i in seq_along(selection_model_5th_percentiles_of_H_e_files_HO)) {
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(selection_model_5th_percentiles_of_H_e_files_HO[i]))
  # Read the .tsv file into a data frame
  subtable <- read.table(selection_model_5th_percentiles_of_H_e_files_HO[i], header = TRUE,sep = "\t", stringsAsFactors = FALSE)
  H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files_HO[i]
  # Add the subtable to the list with the selection coefficient as its name
  H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$results <- subtable
}
# # View the H_e_5th_percentiles_Selection_models_HO
# H_e_5th_percentiles_Selection_models_HO
# Calculating Average F_ROH for each table
# Loop through each selection_coefficient
for (selection_coefficient in names(H_e_5th_percentiles_Selection_models_HO)) {
  # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
  H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
  # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
  # Store the bootstrap confidence interval in the H_e_5th_percentiles_Selection_models_HO table
  H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models_HO[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
}
# # View the dataframe
# View(H_e_5th_percentiles_Selection_models_HO)

```
## 3.3 Sams Selection Model
```{r echo = FALSE,warning = FALSE}
cat("Uncommented because change of analysis")
setwd(Selection_model_H_e_dir_SAMS)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
selection_model_5th_percentiles_of_H_e_files_SAMS <- list.files(path = Selection_model_H_e_dir_SAMS, pattern = pattern)
# selection_model_5th_percentiles_of_H_e_files_SAMS
# Initialize an empty list to store H_e_5th_percentiles_Selection_models_SAMS
H_e_5th_percentiles_Selection_models_SAMS <- list()
# Loop through each selection coefficient and its associated file
for (i in seq_along(selection_model_5th_percentiles_of_H_e_files_SAMS)) {
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(selection_model_5th_percentiles_of_H_e_files_SAMS[i]))
  # Read the .tsv file into a data frame
  subtable <- read.table(selection_model_5th_percentiles_of_H_e_files_SAMS[i], header = TRUE,sep = "\t", stringsAsFactors = FALSE)
  H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files_SAMS[i]
  # Add the subtable to the list with the selection coefficient as its name
  H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$results <- subtable
}
# # View the H_e_5th_percentiles_Selection_models_SAMS
# H_e_5th_percentiles_Selection_models_SAMS
# Calculating Average F_ROH for each table
# Loop through each selection_coefficient
for (selection_coefficient in names(H_e_5th_percentiles_Selection_models_SAMS)) {
  # Calculate the point estimate F_ROH across all 20 simulations for the current selection coefficient
  H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
  # Calculate the bootstrap confidence interval of the point estimate F_ROH across all 20 simulations for the current selection coefficient
  # Store the bootstrap confidence interval in the H_e_5th_percentiles_Selection_models_SAMS table
  H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models_SAMS[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
}
# # View the dataframe
# View(H_e_5th_percentiles_Selection_models_SAMS)

```

## 3.4 Genomewide Average H_e
```{r Expected Heterozygosity Avg H_e Summary, echo = FALSE,warning = FALSE}
# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_HO <- c()
# selection_model_lower_ci_HO <- c()
# selection_model_upper_ci_HO <- c()
# selection_model_names_HO <- c(rownames(summary(H_e_5th_percentiles_Selection_models_HO)))
# 
# # Loop through each selection_coefficient in H_es_Selection_models
# for (selection_coefficient in H_e_5th_percentiles_Selection_models_HO) {
#   selection_coefficient$Estimated_Mean_Population_H_e <- mean(selection_coefficient$results$Avg_H_e)
#   CI <- standard_error_confidence_interval_fun(selection_coefficient$results$Avg_H_e)
# 
#   # Append values to the lists
#   selection_model_avg_values_HO <- c(selection_model_avg_values_HO, selection_coefficient$Estimated_Mean_Population_H_e)
#   selection_model_lower_ci_HO <- c(selection_model_lower_ci_HO, CI[1])
#   selection_model_upper_ci_HO <- c(selection_model_upper_ci_HO, CI[2])
# }
# 
# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_SAMS <- c()
# selection_model_lower_ci_SAMS <- c()
# selection_model_upper_ci_SAMS <- c()
# selection_model_names_SAMS <- c(rownames(summary(H_e_5th_percentiles_Selection_models_SAMS)))
# 
# # Loop through each selection_coefficient in H_es_Selection_models
# for (selection_coefficient in H_e_5th_percentiles_Selection_models_SAMS) {
#   selection_coefficient$Estimated_Mean_Population_H_e <- mean(selection_coefficient$results$Avg_H_e)
#   CI <- standard_error_confidence_interval_fun(selection_coefficient$results$Avg_H_e)
# 
#   # Append values to the lists
#   selection_model_avg_values_SAMS <- c(selection_model_avg_values_SAMS, selection_coefficient$Estimated_Mean_Population_H_e)
#   selection_model_lower_ci_SAMS <- c(selection_model_lower_ci_SAMS, CI[1])
#   selection_model_upper_ci_SAMS <- c(selection_model_upper_ci_SAMS, CI[2])
# }
# 
# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model_HO$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model_HO[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model_HO$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_HO[["results"]][["Avg_H_e"]])

# Calculate the  standard deviation across all 20 simulations
H_e_5th_percentiles_Neutral_model_HO$H_e_Standard_deviation <- standard_deviation_fun(H_e_5th_percentiles_Neutral_model_HO[["results"]][["Avg_H_e"]])


neutral_avg_H_e_HO <- H_e_5th_percentiles_Neutral_model_HO$Estimated_Mean_Population_H_e 
neutral_lower_ci_HO <- H_e_5th_percentiles_Neutral_model_HO$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci_HO <- H_e_5th_percentiles_Neutral_model_HO$SE_CI_Estimated_Mean_H_e[2]
neutral_standard_deviation_HO <- H_e_5th_percentiles_Neutral_model_HO$H_e_Standard_deviation
neutral_HO_Coefficient_of_Variation <- 100*(neutral_standard_deviation_HO/neutral_avg_H_e_HO)

# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model_SAMS$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model_SAMS[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model_SAMS$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model_SAMS[["results"]][["Avg_H_e"]])
# Calculate the  standard deviation across all 20 simulations
H_e_5th_percentiles_Neutral_model_SAMS$H_e_Standard_deviation <- standard_deviation_fun(H_e_5th_percentiles_Neutral_model_SAMS[["results"]][["Avg_H_e"]])

neutral_avg_H_e_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS$Estimated_Mean_Population_H_e 
neutral_lower_ci_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS$SE_CI_Estimated_Mean_H_e[2]
neutral_standard_deviation_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS$H_e_Standard_deviation
neutral_SAMS_Coefficient_of_Variation <- 100*(neutral_standard_deviation_SAMS/neutral_avg_H_e_SAMS)


# Extract empirical model value
empirical_avg_H_e <- empirical_H_e_distribution_table$Avg_H_e
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
empirical_standard_deviation <- NA # Placeholder value
empirical_Coefficient_of_Variation <- NA # Placeholder value

neutral_model_H_e_error_perc_HO <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_HO$Estimated_Mean_Population_H_e/empirical_H_e_distribution_table$Avg_H_e)))
                                     ,H_e_values_decimals)

neutral_model_H_e_error_perc_SAMS <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_SAMS$Estimated_Mean_Population_H_e/empirical_H_e_distribution_table$Avg_H_e)))
                                     ,H_e_values_decimals)
empirical_H_e_error_perc <- NA # Placeholder 


# Combine all values into a data frame
H_e_values <- data.frame(
  Model = c("Neutral - Sams ","Neutral - HO", "Empirical"),
  H_e = c(neutral_avg_H_e_SAMS, neutral_avg_H_e_HO, empirical_avg_H_e),
  Lower_CI = c(neutral_lower_ci_SAMS, neutral_lower_ci_HO, empirical_lower_ci),
  Upper_CI = c(neutral_upper_ci_SAMS, neutral_upper_ci_HO, empirical_upper_ci),
  Standard_Deviation = c(neutral_standard_deviation_SAMS,neutral_standard_deviation_HO,empirical_standard_deviation),
  Coefficient_of_variation = c(neutral_SAMS_Coefficient_of_Variation,neutral_HO_Coefficient_of_Variation,empirical_Coefficient_of_Variation),
  Error_percentage = c(neutral_model_H_e_error_perc_SAMS,neutral_model_H_e_error_perc_HO,empirical_H_e_error_perc)
)

# Format all numeric values to 5 decimal places
H_e_values$H_e <- round(H_e_values$H_e, H_e_values_decimals)
H_e_values$Lower_CI <- round(H_e_values$Lower_CI,H_e_values_decimals)
H_e_values$Upper_CI <- round(H_e_values$Upper_CI,H_e_values_decimals)
H_e_values$Error_percentage <- round(H_e_values$Error_percentage,Error_percentage_decimals)
H_e_values$Standard_Deviation <- round(H_e_values$Standard_Deviation,Standard_deviation_decimals)
H_e_values$Coefficient_of_variation <- round(H_e_values$Coefficient_of_variation,Error_percentage_decimals)
# # Update the Model column for selection models
# H_e_values$Model[1:length(selection_model_names)] <- selection_model_names

# Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient

# # formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_model_names)
# formatted_selection_coefficient_labels <-sub("s(\\d)(\\d+)_.*", "s=\\1.\\2", selection_model_names)
# formatted_selection_coefficient_labels <- sub("selection_model_", "", formatted_selection_coefficient_labels)
# H_e_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels

H_e_values$H_e <- as.numeric(round(H_e_values$H_e,H_e_values_decimals))
# Sort the data frame based on H_e column
H_e_values_sorted <- H_e_values[order(as.numeric(H_e_values$H_e)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_NO_MAF_Genomic_Average_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_values,
#   sort_column = "H_e",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )
# Print the table using knitr::kable()
knitr::kable(H_e_values_sorted, row.names = FALSE)

```



## 3.5 Genomewide 5th percentile comparison - Expected Heterozygosity Summary

```{r Expected Heterozygosity 5th percentile Summary, echo = FALSE,warning = FALSE}

# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_HO <- c()
# selection_model_lower_ci_HO <- c()
# selection_model_upper_ci_HO <- c()
# 
# # Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models_HO
# for (selection_coefficient in H_e_5th_percentiles_Selection_models_HO) {
#   CI <- selection_coefficient$SE_CI_Estimated_Mean_H_e_5th_percentile
# 
#   # Append values to the lists
#   selection_model_avg_values_HO <- c(selection_model_avg_values_HO, selection_coefficient$Estimated_Mean_H_e_5th_percentile)
#   selection_model_lower_ci_HO <- c(selection_model_lower_ci_HO, CI[1])
#   selection_model_upper_ci_HO <- c(selection_model_upper_ci_HO, CI[2])
# }
# 
# # Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
# selection_model_avg_values_SAMS <- c()
# selection_model_lower_ci_SAMS <- c()
# selection_model_upper_ci_SAMS <- c()
# 
# # Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models_SAMS
# for (selection_coefficient in H_e_5th_percentiles_Selection_models_SAMS) {
#   CI <- selection_coefficient$SE_CI_Estimated_Mean_H_e_5th_percentile
# 
#   # Append values to the lists
#   selection_model_avg_values_SAMS <- c(selection_model_avg_values_SAMS, selection_coefficient$Estimated_Mean_H_e_5th_percentile)
#   selection_model_lower_ci_SAMS <- c(selection_model_lower_ci_SAMS, CI[1])
#   selection_model_upper_ci_SAMS <- c(selection_model_upper_ci_SAMS, CI[2])
# }
# 


# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile_HO <- H_e_5th_percentiles_Neutral_model_HO[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci_HO <- H_e_5th_percentiles_Neutral_model_HO[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci_HO <- H_e_5th_percentiles_Neutral_model_HO[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]

# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci_SAMS <- H_e_5th_percentiles_Neutral_model_SAMS[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]


# Extract empirical model value
empirical_avg_H_e_5th_percentile <- empirical_H_e_distribution_table$Fifth_Percentile
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound


# Extract neutral model values and CI bounds

neutral_model_H_e_5th_percentiles_error_perc_HO <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_HO[["Estimated_Mean_H_e_5th_percentile"]]/empirical_H_e_distribution_table$Fifth_Percentile)))
                                     ,H_e_values_decimals)

neutral_model_H_e_5th_percentiles_error_perc_SAMS <- round(100*( abs( 1-(H_e_5th_percentiles_Neutral_model_SAMS[["Estimated_Mean_H_e_5th_percentile"]]/empirical_H_e_distribution_table$Fifth_Percentile)))
                                     ,H_e_values_decimals)

empirical_H_e_5th_percentiles_error_perc_SAMS <- NA # Placeholder

# Combine all values into a data frame
H_e_5th_percentile_values <- data.frame(
  Model = c("Neutral - Sams", "Neutral - HO", "Empirical"),
  H_e_5th_percentile = c(neutral_avg_H_e_5th_percentile_SAMS, neutral_avg_H_e_5th_percentile_HO, empirical_avg_H_e_5th_percentile),
  Lower_CI = c(neutral_lower_ci_SAMS, neutral_lower_ci_HO, empirical_lower_ci),
  Upper_CI = c(neutral_upper_ci_SAMS, neutral_upper_ci_HO, empirical_upper_ci),
  Error_perc = c(neutral_model_H_e_5th_percentiles_error_perc_SAMS,neutral_model_H_e_5th_percentiles_error_perc_HO,empirical_H_e_5th_percentiles_error_perc_SAMS)
)

# Format all numeric values to 5 decimal places
H_e_5th_percentile_values$H_e_5th_percentile <- round(H_e_5th_percentile_values$H_e_5th_percentile, H_e_values_decimals)
H_e_5th_percentile_values$Lower_CI <- round(H_e_5th_percentile_values$Lower_CI,H_e_values_decimals)
H_e_5th_percentile_values$Upper_CI <- round(H_e_5th_percentile_values$Upper_CI,H_e_values_decimals)
H_e_5th_percentile_values$Error_perc <- round(H_e_5th_percentile_values$Error_perc,Error_percentage_decimals)





# # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
# # formatted_selection_coefficient_labels <- sub("^.*_s(0?)(\\d+)_chr\\d+$", "s=\\1.\\2", selection_model_names)
# formatted_selection_coefficient_labels <-sub("s(\\d)(\\d+)_.*", "s=\\1.\\2", selection_model_names)
# H_e_5th_percentile_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels
H_e_5th_percentile_values$H_e_5th_percentile <- as.numeric(round(H_e_5th_percentile_values$H_e_5th_percentile,H_e_values_decimals))

# Sort the data frame based on H_e_5th_percentile column
H_e_5th_percentile_values_sorted <- H_e_5th_percentile_values[order(as.numeric(H_e_5th_percentile_values$H_e_5th_percentile)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("HO_evaluation_NO_MAF_5th_percentile_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_5th_percentile_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_5th_percentile_values,
#   sort_column = "H_e_5th_percentile",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )

# Print the table using knitr::kable()
knitr::kable(H_e_5th_percentile_values_sorted, row.names = FALSE)

```

# 4: Summary
## 4.0 General comparison
### 4.0.1 ROH-hotspot threshold comparison
```{r echo = FALSE,warning = FALSE}

# cat("\n ROH-hotspot threshold comparison between the different datasets")
# # Print the table using knitr::kable()
# knitr::kable(ROH_hotspot_threshold_values_sorted, row.names = FALSE)
# ```
# ### 4.0.2 F_ROH comparison
# ```{r echo = FALSE,warning = FALSE}
# setwd(output_dir)
# 
# # Creating an image of the F_ROH plot
# # png(filename = "Population_F_ROH_comparison_with_CI.png", width = 800, height = 600, res = 300)
# png(filename = "Population_F_ROH_comparison_with_CI.png",width = 1920, height = 1080, res = 300)
# 
# 
# # Remove the empirical model from the plotting data
# plotting_data <- F_ROH_values[F_ROH_values$Model != "Empirical", ]
# 
# # Add a column indicating whether the empirical F_ROH is within the CI of each model
# empirical_F_ROH <- empirical_avg_F_ROH
# plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_F_ROH) & (plotting_data$Upper_CI >= empirical_F_ROH)
# 
# # Create the plot
# p <- ggplot(plotting_data, aes(x = Model, y = F_ROH, color = Empirical_Within_CI)) +
#   geom_point(size = 3) +
#   geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
#   # Force the empirical F_ROH line to always be shown
#   geom_hline(aes(yintercept = empirical_F_ROH), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
#   labs(title = "F_ROH Values and Confidence Intervals by Model",
#        x = "Model",
#        y = "F_ROH",
#        color = "Empirical F_ROH\nwithin CI",
#        linetype = "Empirical F_ROH") +
#   scale_linetype_manual(name = "Empirical F_ROH", values = c("dashed")) +
#   scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
# 
# # Print the plot
# print(p)

# # Print which models the empirical F_ROH is inside of
# inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
# outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
# 
# cat("Models where empirical F_ROH is within CI:\n")
# print(inside_models)
# cat("\nModels where empirical F_ROH is outside CI:\n")
# print(outside_models)
# 
# # Close the graphics device
# dev.off()

## Print the table using knitr::kable()
# knitr::kable(F_ROH_values_sorted, row.names = FALSE)

```

## 4.1: Hotspot comparison

### 4.1.1: Selection test (Sweep test)

```{r Sweep test, echo = FALSE,warning = FALSE}
# setwd(Sweep_test_dir_HO)
# # Pattern for finding files containing "F_ROH" and ending with ".tsv"
# pattern <- "^.*neutral_model.*.tsv$"
# selection_testing_files <- list.files(path = Sweep_test_dir_HO, pattern = pattern)
# # selection_testing_files
# 
# # Extracting the ROH-hotspot threshold value from the suffix of the filename
# parts <- unlist(strsplit(selection_testing_files[1], "threshold_")) # Split the string by "threshold_"
# # Extract the decimal number using regular expressions
# fifth_percentile_H_e_neutral_model <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
# 
# 
# for (file in selection_testing_files) {
#   
#   file_name <- file
# 
#   # Read the header line
#   con <- file(file, "r")
#   header <- readLines(con, n = 1)
#   close(con)
# 
#   # Remove "#" from the header and split it into column names
#   column_names <- sub("#", "", header)
#   column_names <- strsplit(column_names, "\t")[[1]]
# 
#   
#   # # Read the .tsv frequency file into a data frame
#   Selection_testing_results <- read.table(selection_testing_files, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
#   Selection_testing_results[3] <- round(Selection_testing_results[3],H_e_values_decimals)
#   # Remove "_allele_freq" from the names
#   Selection_testing_results$Name <- gsub("_allele_freq$", "", Selection_testing_results$Name)
# 
# }
# paste0("Selection test results")
# paste0("ROH-hotspot windows with an mean H_e Value lower or equal to the lower confidence interval of the fifth percentile of the neutral model are classified as being under selection")
# paste0("5th percentile of the neutral model is: ",fifth_percentile_H_e_neutral_model)
# # Print the table using knitr::kable()
# knitr::kable(Selection_testing_results, row.names = FALSE) 
# 
# formatted_selection_H_e_threshold <- round(fifth_percentile_H_e_neutral_model,H_e_values_decimals)
# 
# 
# #Define the filename with the output directory path
# filename_csv <- file.path(output_dir, paste("ROH_hotspots_Sweep_test_H_E_threshold_",formatted_selection_H_e_threshold,".csv", sep = ""))
# 
# Selection_testing_results_latex <- Selection_testing_results
# # Escape underscores in the Name column
# Selection_testing_results_latex$Name <- gsub("_", "\\_", Selection_testing_results_latex$Name, fixed = TRUE)
# 
# # # Write data to CSV file without quotes
# # write.table(Selection_testing_results_latex, file = filename_csv, sep = ",", row.names = FALSE, quote = FALSE)
# # 
# # # Define the filename with the output directory path
# # filename <- file.path(paste("ROH_hotspots_Selection_testing_neutral_model_H_E_threshold_",formatted_selection_H_e_threshold,".csv", sep = ""))
# 
# 
# # # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# # write_latex_table(
# #   data_frame = Selection_testing_results,
# #   sort_column = "Window_based_Average_H_e",  #
# #   output_dir = output_dir,
# #   output_filename = filename  
# # )
# 
# 
# # Subset the dataframe to extract rows where Under_selection is "Yes"
# under_selection_rows <- subset(Selection_testing_results, Under_selection == "Yes")
# paste0("ROH-hotspots under selection:")
# knitr::kable(under_selection_rows, row.names = FALSE) 
# #View(Selection_testing_results)
# 


```

#### 4.1.1.1 Extracting Causative windows under selection
```{r ,echo = FALSE,warning = FALSE}
# # Initialize vectors to store H_e values and CI bounds for the different selection coefficients
# selection_model_avg_values <- c()
# selection_model_lower_ci <- c()
# selection_model_upper_ci <- c()
# selection_model_names <- c()
# 
# # Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models
# for (selection_coefficient in names(window_H_e_causative_variant_tables)) {
#     # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
#   formatted_selection_coefficient_labels <- sub("s(\\d)(\\d+)_.*", "s=\\1.\\2", selection_coefficient)
# 
#   CI <- window_H_e_causative_variant_tables[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_H_e
# 
#   # Append values to the lists
#   selection_model_names <- c(selection_model_names,formatted_selection_coefficient_labels)
#   selection_model_avg_values <- c(selection_model_avg_values, window_H_e_causative_variant_tables[[selection_coefficient]]$Estimated_Mean_Population_H_e)
#   selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
#   selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
# }
# 
# # Extract neutral model values and CI bounds
# neutral_avg_H_e_5th_percentile <- H_e_5th_percentiles_Neutral_model[["Estimated_Mean_H_e_5th_percentile"]]
# neutral_lower_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
# neutral_upper_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]
# 
# # Combine all values into a data frame
# H_e_values <- data.frame(
#   Model = c(selection_model_names, "Neutral"),
#   H_e = c(selection_model_avg_values, neutral_avg_H_e_5th_percentile),
#   Lower_CI = c(selection_model_lower_ci, neutral_lower_ci),
#   Upper_CI = c(selection_model_upper_ci, neutral_upper_ci)
# )
# 
# # Format all numeric values to have the number of decimals defined by H_e_values_decimals
# H_e_values$H_e <- round(H_e_values$H_e,H_e_values_decimals)
# H_e_values$Lower_CI <- as.numeric(round(H_e_values$Lower_CI,H_e_values_decimals))
# H_e_values$Upper_CI <- as.numeric(round(H_e_values$Upper_CI,H_e_values_decimals))
# 
# # # Update the Model column for selection models
# H_e_values$Model[1:length(selection_model_names)] <- selection_model_names
# 
# # Extract labels for the different selection coefficients
# selection_labels <- gsub(".*_(s\\d+)_.*", "\\1", selection_model_names)
# # H_e_values$Model[1:length(selection_model_names)] <- selection_labels
# 
# 
# # Add a new column 'under_selection' to the data frame
# H_e_values$Under_Selection <- ifelse(H_e_values$H_e < neutral_lower_ci, "Yes", "No")
# 
# # Filter the rows where 'under_selection' is 'Yes' and exclude 'Neutral'
# Causative_windows_under_selection <- subset(H_e_values, Under_Selection == "Yes" & Model != "Neutral")
# Causative_windows_under_selection <- Causative_windows_under_selection[, -which(names(Causative_windows_under_selection) == "Under_Selection")]
# 
# # Sort the results table based on H_e
# H_e_values_sorted <- H_e_values[order(as.numeric(H_e_values$H_e)), ]
# 
# 
# # # Define the filename with the output directory path
# # filename <- file.path(output_dir, paste("Causative_windows_under_selection",".csv", sep = ""))
# # 
# # # Write data to CSV file without quotes
# # write.table(H_e_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# # 
# # # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# # write_latex_table(
# #   data_frame = H_e_values,
# #   sort_column = "H_e",  # Column used for sorting
# #   output_dir = output_dir,
# #   output_filename = "Causative_windows_under_selection"  
# # )
# 
# # Print the table using knitr::kable()
# knitr::kable(H_e_values_sorted, row.names = FALSE)

```


#### 4.1.1.1 Extracting Hotspots under selection
```{r echo = FALSE,warning = FALSE}
# # Initialize an empty list to store the new table
# hotspot_under_selection_H_e_table <- list()
# 
# # If no Hotspot is under selection, then display all hotspots instead
# if (nrow(under_selection_rows) == 0) {
#   under_selection_rows <- Selection_testing_results
# }
# 
# 
# # Loop through each row in under_selection_rows
# for (i in 1:nrow(under_selection_rows)) {
#   # Extract information for the current ROH-hotspot window
#   current_window <- under_selection_rows[i, "Name"]
#   under_selection <- under_selection_rows[i, "Under_selection"]
#   Hotspot_Avg_H_e <- under_selection_rows[i, "Window_based_Average_H_e"]
#   
#   
# 
#   # Initialize a subtable for the current ROH-hotspot window
#   subtable <- list()
#   
#   # Remove the 'Under_Selection' column from the table
#   subtable <- Causative_windows_under_selection
# 
#   # Create a list with table name and corresponding data frame
#   table_info <- list(Hotspot_Avg_H_e = Hotspot_Avg_H_e, coefficient_data = subtable)
#   # Add the subtable for the current ROH-hotspot window to the new table
#   hotspot_under_selection_H_e_table[[current_window]] <- c(hotspot_under_selection_H_e_table[[current_window]],table_info)
#   # hotspot_under_selection_H_e_table[[current_window]]$Hotspot_Avg_H_e <- Hotspot_Avg_H_e
# }
# 
# # View the new table
# View(hotspot_under_selection_H_e_table)
```






