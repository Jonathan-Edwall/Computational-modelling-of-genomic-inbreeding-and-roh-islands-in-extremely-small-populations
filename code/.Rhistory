col = "blue", lty = 2, cex = 0.8, text.col = "black")
cat("ROH-hotspot selection testing results:\n")
kable(ROH_hotspots_selection_testing, row.names = FALSE)
# # Saving the results in a .tsv-file
# write.table(ROH_hotspots_selection_testing, "ROH_hotspots_selection_testing_results.tsv", sep = "\t", row.names = FALSE,quote = FALSE)
# Determine the number of bins you want
num_bins <- 100
# Initialize an empty data frame to store the results
sim_5th_percentiles_df <- data.frame(Simulation = character(), Fifth_Percentile = numeric(), stringsAsFactors = FALSE)
# Remove row names from sim_5th_percentiles_df
rownames(sim_5th_percentiles_df) <- NULL
# Loop through each simulation
for (i in seq_along(Simulation_windows_avg_he_3_2)) {
# Create histogram title
histogram_title <- paste("H_e Distribution of Simulation", i, "- Windowsize:", window_size, "bp")
# Create a histogram with custom breaks
hist(Simulation_windows_avg_he_3_2[[i]], breaks = num_bins, main = histogram_title, xlab = "H_e")
# Calculate the 5th percentile
percentile_5 <- quantile(Simulation_windows_avg_he_3_2[[i]], 0.05)
neutral_model_tables[[i]]$H_e_5th_percentile <- percentile_5
# Add the simulation name and the fifth percentile value to the data frame
sim_5th_percentiles_df[i, "Simulation"] <- paste("Simulation", i)
sim_5th_percentiles_df[i, "Fifth_Percentile"] <- percentile_5
# Add a vertical line at the 5th percentile
abline(v = percentile_5, col = "red", lty = 2)
# Add a legend
legend("topright", legend = paste("5th percentile =", round(percentile_5, 4)), col = "red", lty = 2)
}
# Sort the data frame by Fifth_Percentile values in ascending order
sim_5th_percentiles_df <- sim_5th_percentiles_df[order(sim_5th_percentiles_df$Fifth_Percentile), ]
print(sim_5th_percentiles_df)
# Print the data frame
kable(sim_5th_percentiles_df)
# Clean the working environment
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
# Set the path to your GitHub folder
YOUR_GITHUB_ROOT_DIRECTORY <- "C:/Users/jonat/GitHub"
# Defining the relative path in the repository
repository_path <- "Computational-modelling-of-genomic-inbreeding-and-roh-islands-in-extremely-small-populations"
####################################
# Defining the input files
####################################
ROH_hotspot_allele_freq_dir <- file.path(YOUR_GITHUB_ROOT_DIRECTORY, repository_path,"results/ROH-Hotspots/empirical/german_shepherd/gosling_plots/hotspots_allele_freq")
empirical_genomewide_allele_freq_dir <- file.path(YOUR_GITHUB_ROOT_DIRECTORY, repository_path,"results/PLINK//empirical/german_shepherd/allele_freq")
neutral_model_allele_freq_dir <- file.path(YOUR_GITHUB_ROOT_DIRECTORY, repository_path,"results/PLINK/simulated/allele_freq")
####################################
# Defining the working directory
####################################
output_dir_sweep_test <- file.path(YOUR_GITHUB_ROOT_DIRECTORY, repository_path,"results/Sweep_test/german_shepherd")
if (!dir.exists(output_dir_sweep_test)) {
# Create the working directory if it doesn't exist
dir.create(output_dir_sweep_test,recursive = TRUE)
}
# Set the working directory for notebook chunks
knitr::opts_knit$set(root.dir = output_dir_sweep_test)
library(knitr)
# Set the working directory to the directory with allele frequencies for the different ROH-hotspots
setwd(ROH_hotspot_allele_freq_dir)
# Get a list of all .bed files in the directory
bed_files <- list.files(pattern = "\\.bed$")
# Create an empty list to store information for the different ROH-hotspots in
empirical_hotspot_tables <- list()
# Loop through each .bed file (ROH-hotspot allele frequency window-file)
for (file in bed_files) {
# Extract chromosome number and window number from file name
chromosome <- sub(".*chr([0-9]+)_.*", "\\1", file)
window <- sub(".*window_([0-9]+)_.*", "\\1", file)
# Create table name
table_name <- paste("Hotspot_chr", chromosome, "_window_", window, "_allele_freq", sep = "")
# Read the header line
con <- file(file, "r")
header <- readLines(con, n = 1)
close(con)
# Remove "#" from the header and split it into column names
column_names <- sub("#", "", header)
column_names <- strsplit(column_names, "\t")[[1]]
# Read the .bed file into a data frame, skipping commented lines
bed_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
# Create a list with table name and corresponding data frame
table_info <- list(name = table_name, data = bed_data)
# Append the table info to the list
empirical_hotspot_tables <- c(empirical_hotspot_tables, list(table_info))
}
# Print the list of empirical_hotspot_tables
#print(empirical_hotspot_tables)
# Set the working directory to the directory with allele frequencies for the different ROH-genomewides
setwd(empirical_genomewide_allele_freq_dir)
# Get a list of all .bed files in the directory
bed_files <- list.files(pattern = "\\.bed$")
# Create an empty list to store information for the different ROH-genomewides in
empirical_genomewide_tables <- list()
# Loop through each .bed file (ROH-genomewide allele frequency window-file)
for (file in bed_files) {
# Extract chromosome number and window number from file name
chromosome <- sub(".*chr([0-9]+)_.*", "\\1", file)
window <- sub(".*window_([0-9]+)_.*", "\\1", file)
# Create table name
table_name <- paste("Hotspot_chr", chromosome, "_window_", window, "_allele_freq", sep = "")
# Read the header line
con <- file(file, "r")
header <- readLines(con, n = 1)
close(con)
# Remove "#" from the header and split it into column names
column_names <- sub("#", "", header)
column_names <- strsplit(column_names, "\t")[[1]]
# Read the .bed file into a data frame, skipping commented lines
bed_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
# Create a list with table name and corresponding data frame
table_info <- list(name = table_name, data = bed_data)
# Append the table info to the list
empirical_genomewide_tables <- c(empirical_genomewide_tables, list(table_info))
}
# Print the list of empirical_genomewide_tables
print(empirical_genomewide_tables)
# Set the working directory to the directory containing the frequency files for the simulated data
setwd(neutral_model_allele_freq_dir)
# Get a list of all the .tsv frequency files in the current directory
# (these .tsv files are identical to the .frq files, but with a POS-column added, to associate the SNP-markers with a genomic position)
frq_files <- list.files(pattern = "\\.tsv$")
# Extract the simulation number after "sim_"
simulation_numbers <- as.integer(sub("^sim_(\\d+)_.*", "\\1", frq_files))
# Sort the simulation-files based on the simulation number
sorted_files <- frq_files[order(simulation_numbers)]
# Initialize an empty list to store neutral model tables
neutral_model_tables <- list()
# Loop through each .frq file
for (file in sorted_files) {
# Extract the table name from the file name
table_name <- gsub(".frq$", "", file)
# Read the header line
con <- file(file, "r")
header <- readLines(con, n = 1)
close(con)
# Remove "#" from the header and split it into column names
column_names <- sub("#", "", header)
column_names <- strsplit(column_names, "\t")[[1]]
# Read the .tsv frequency file into a data frame
#frq_data <- read.table(file, header = TRUE)
frq_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
# Create a list with table name and corresponding data frame
table_info <- list(name = table_name, data = frq_data)
# Append the table info to the list
neutral_model_tables <- c(neutral_model_tables, list(table_info))
}
# Print the list of neutral_model_tables
#print(neutral_model_tables)
calculate_expected_heterozygosity <- function(p) {
# Calculate expected heterozygosity
heterozygosity <- 2 * p * (1 - p)
# Return the result
return(heterozygosity)
}
for (i in seq_along(empirical_hotspot_tables)) {
# Extract table name and data frame
table_info <- empirical_hotspot_tables[[i]]
table_data <- table_info$data
# Calculate expected heterozygosity for each window
window_H_e_list <- c()  # Initialize an empty list to store expected heterozygosity values
# Loop through each row in the table data
for (j in 1:nrow(table_data)) {
# Extract the MAF (p value)
p <- table_data[j, "MAF"]
# Calculate expected heterozygosity using the provided function
expected_heterozygosity <- calculate_expected_heterozygosity(p)
# Append the calculated expected heterozygosity to the list
window_H_e_list <- c(window_H_e_list, expected_heterozygosity)
}
# Assign the calculated expected heterozygosity list to the H_e attribute of table_info
empirical_hotspot_tables[[i]]$H_e_list <- window_H_e_list
empirical_hotspot_tables[[i]]$Average_H_e <- mean(empirical_hotspot_tables[[i]]$H_e_list)
}
View(empirical_hotspot_tables)
for (i in seq_along(empirical_genomewide_tables)) {
# Extract table name and data frame
table_info <- empirical_genomewide_tables[[i]]
table_data <- table_info$data
# Calculate expected heterozygosity for each window
window_H_e_list <- c()  # Initialize an empty list to store expected heterozygosity values
# Loop through each row in the table data
for (j in 1:nrow(table_data)) {
# Extract the MAF (p value)
p <- table_data[j, "MAF"]
# Calculate expected heterozygosity using the provided function
expected_heterozygosity <- calculate_expected_heterozygosity(p)
# Append the calculated expected heterozygosity to the list
window_H_e_list <- c(window_H_e_list, expected_heterozygosity)
}
# Assign the calculated expected heterozygosity list to the H_e attribute of table_info
empirical_genomewide_tables[[i]]$H_e_list <- window_H_e_list
empirical_genomewide_tables[[i]]$Average_H_e <- mean(empirical_genomewide_tables[[i]]$H_e_list)
}
View(empirical_genomewide_tables)
# create a vector to store the counts of pruned entries for each simulation
pruned_counts <- numeric(length(neutral_model_tables))
datapoints_before_MAF_filtering <- numeric(length(neutral_model_tables))
#sum(neutral_model_tables[[1]][["data"]][["MAF"]] < 0.05)
#sum(neutral_model_tables[[20]][["data"]][["MAF"]] < 0.05)
for (i in seq_along(neutral_model_tables)) {
# Extract table name and data frame
table_info <- neutral_model_tables[[i]]
table_data <- table_info$data
datapoints_before_MAF_filtering[[i]] <- length(table_data$MAF)
# Calculate expected heterozygosity for each window
window_H_e_list <- c()  # Initialize an empty list to store expected heterozygosity values
#create a vector to store the indices of rows to be removed based on having MAF < 0.05 threshold
rows_to_remove <- c()
# Looping through each row in the table data
for (j in 1:nrow(table_data)) {
# Extract the MAF (p value)
p <- table_data[j, "MAF"]
# Check if MAF is less than 0.05
if (p < 0.05) {
# If MAF is less than 0.05, add the row index to the vector of rows to be removed
rows_to_remove <- c(rows_to_remove, j)
} else {
# Calculate expected heterozygosity using the provided function
expected_heterozygosity <- calculate_expected_heterozygosity(p)
# Append the calculated expected heterozygosity to the list
window_H_e_list <- c(window_H_e_list, expected_heterozygosity)
}
}
# Remove rows from neutral_model_tables with MAF less than 0.05
table_data_filtered <- table_data[-rows_to_remove, ]
neutral_model_tables[[i]]$data <- table_data_filtered
# Assign the calculated expected heterozygosity list to the H_e attribute of table_info
neutral_model_tables[[i]]$H_e_list <- window_H_e_list
neutral_model_tables[[i]]$Average_H_e <- mean(neutral_model_tables[[i]]$H_e_list)
# Update the count of pruned entries for this simulation
pruned_counts[i] <- length(rows_to_remove)
}
paste("Snps for each simulation, before the pruning:",datapoints_before_MAF_filtering)
paste("Pruned SNPs:",pruned_counts)
View(neutral_model_tables)
# Define the window size to be used
window_size <- 100 * 10^3
#window_size <- 2000 * 10^3
########################################################################
# Step 1: Create genomic windows
########################################################################
# Initialize an empty list to store windows for each empirical_genomewide
empirical_genomewide_windows <- list()
# Iterating through each empirical_genomewide
for (index in seq_along(empirical_genomewide_tables)) {
# Get the SNP positions, chromosome positions, and H_e values for the current empirical_genomewide
snp_positions <- empirical_genomewide_tables[[index]][["data"]][["POS1"]]
chr_positions <- empirical_genomewide_tables[[index]][["data"]][["CHR"]]
he_values <- empirical_genomewide_tables[[index]][["H_e_list"]]
# Determine unique chromosomes present in the data
unique_chromosomes <- unique(chr_positions)
# Iterate through each chromosome
for (chromosome in unique_chromosomes) {
# Filter SNP positions and H_e values for the current chromosome
chr_snp_positions <- snp_positions[chr_positions == chromosome]
chr_he_values <- he_values[chr_positions == chromosome]
# Determine the number of windows needed for the current chromosome
num_windows <- ceiling(max(chr_snp_positions) / window_size)
# Initialize an empty list to store windows for the current chromosome
chr_windows <- list()
# Iterate through each window
for (window_index in seq_len(num_windows)) {
# Determine the start and end positions of the current window
window_start <- (window_index - 1) * window_size
window_end <- window_start + window_size
# Find the indices of SNPs within the current window
snp_indices <- which(chr_snp_positions >= window_start & chr_snp_positions < window_end)
# Extract the SNP positions and H_e values for the current window
window_snp_positions <- chr_snp_positions[snp_indices]
window_he_values <- chr_he_values[snp_indices]
# Create a sub-table for the current window
window_data <- data.frame(CHR = rep(chromosome, length(window_snp_positions)), POS = window_snp_positions, H_e = window_he_values)
# Append the sub-table to the list of windows for the current chromosome
chr_windows[[window_index]] <- window_data
}
# Append the list of windows for the current chromosome to the main list
#empirical_genomewide_windows[[chromosome]] <- chr_windows
empirical_genomewide_windows[[chromosome]] <- chr_windows
}
}
# View the resulting windows
View(empirical_genomewide_windows)
#######################################################################
# Step 2: Compute the average H_e for each genomic window individually
#######################################################################
# Create a list to store the average H_e values for each empirical_genomewide
Empirical_genomewide_window_he_3_1 <- list()
# Iterate over each empirical_genomewide
for (i in seq_along(empirical_genomewide_windows)) {
# Create a vector to store the average H_e values for each window in the current empirical_genomewide
Empirical_genomewide_window_he_3_1[[i]] <- numeric(length(empirical_genomewide_windows[[i]]))
# Iterate over each window in the current empirical_genomewide
for (j in seq_along(empirical_genomewide_windows[[i]])) {
# Calculate the average H_e value for the current window
# Using "na.rm = TRUE" To remove windows not having SNP-markers in them
window_avg_he <- mean(empirical_genomewide_windows[[i]][[j]][["H_e"]], na.rm = TRUE)
# Store the average H_e value for the current window
Empirical_genomewide_window_he_3_1[[i]][j] <- window_avg_he
}
# Removing NaN values for the current empirical_genomewide
# (Windows without any markers)
Empirical_genomewide_window_he_3_1[[i]] <- Empirical_genomewide_window_he_3_1[[i]][!is.na(Empirical_genomewide_window_he_3_1[[i]])]
}
View(Empirical_genomewide_window_he_3_1)
# Calculating the mean H_e value for each chromosome
# sapply applies the mean-function on each chr in Simulation_windows_avg_he_3_2
empirical_chromosomes_mean_he_window_based <- sapply(Empirical_genomewide_window_he_3_1, mean)
paste("Average H_e of each chromosome in the empirical dataset:",empirical_chromosomes_mean_he_window_based)
#################################################################################
# Step 3: Compute the genomwide average H_e for the empirical data (window-based)
#################################################################################
empirical_genomewides_mean_he_window_based <- mean(empirical_chromosomes_mean_he_window_based)
cat("Average H_e of the empirical dataset:")
print(empirical_genomewides_mean_he_window_based)
########################################################################
# Step 1: Create genomic windows
########################################################################
# Initialize an empty list to store windows for each simulation
simulation_windows <- list()
# Iterating through each simulation
for (sim_index in seq_along(neutral_model_tables)) {
# Get the SNP positions and H_e values for the current simulation
snp_positions <- neutral_model_tables[[sim_index]][["data"]][["POS"]]
he_values <- neutral_model_tables[[sim_index]][["H_e_list"]]
# Determine the number of windows needed
num_windows <- ceiling(max(snp_positions) / window_size)
# Initialize an empty list to store windows for the current simulation
sim_windows <- list()
# Iterate through each window
for (window_index in seq_len(num_windows)) {
# Determine the start and end positions of the current window
window_start <- (window_index - 1) * window_size
window_end <- window_start + window_size
# Find the indices of SNPs within the current window
snp_indices <- which(snp_positions >= window_start & snp_positions < window_end)
# Extract the SNP positions and H_e values for the current window
window_snp_positions <- snp_positions[snp_indices]
window_he_values <- he_values[snp_indices]
# Create a sub-table for the current window
window_data <- data.frame(POS = window_snp_positions, H_e = window_he_values)
# Append the sub-table to the list of windows for the current simulation
sim_windows[[window_index]] <- window_data
}
# Append the list of windows for the current simulation to the main list
simulation_windows[[sim_index]] <- sim_windows
}
View(simulation_windows)
#######################################################################
# Step 2: Compute the average H_e for each genomic window individually
#######################################################################
# Create a list to store the average H_e values for each simulation
Simulation_windows_avg_he_3_2 <- list()
# Iterate over each simulation
for (i in seq_along(simulation_windows)) {
# Create a vector to store the average H_e values for each window in the current simulation
Simulation_windows_avg_he_3_2[[i]] <- numeric(length(simulation_windows[[i]]))
# Iterate over each window in the current simulation
for (j in seq_along(simulation_windows[[i]])) {
# Calculate the average H_e value for the current window
# Using "na.rm = TRUE" To remove windows not having SNP-markers in them
window_avg_he <- mean(simulation_windows[[i]][[j]][["H_e"]], na.rm = TRUE)
# Store the average H_e value for the current window
Simulation_windows_avg_he_3_2[[i]][j] <- window_avg_he
}
# Removing NaN values for the current simulation
# (Windows without any markers)
Simulation_windows_avg_he_3_2[[i]] <- Simulation_windows_avg_he_3_2[[i]][!is.na(Simulation_windows_avg_he_3_2[[i]])]
}
# Calculate the mean H_e value for each simulation
# sapply applies the mean-function on each chr in Simulation_windows_avg_he_3_2
simulations_mean_he_window_based <- sapply(Simulation_windows_avg_he_3_2, mean)
simulations_mean_he_window_based
# Determine the number of bins you want
num_bins <- 100
histogram_title <-  paste("H_e Distribution of the empirical data - Windowsize:",window_size,"bp")
# Create a histogram with custom breaks
# Using unlist to
hist(unlist(Empirical_genomewide_window_he_3_1), breaks = num_bins, main = histogram_title, xlab = "H_e")
# Calculate the 5th percentile
empirical_dataset_percentile_5 <- quantile(unlist(Empirical_genomewide_window_he_3_1), 0.05)
# Add a vertical line at the 5th percentile
abline(v = empirical_dataset_percentile_5, col = "blue", lty = 2)
# Add a legend
legend("topright", legend = paste("5th percentile =", round(empirical_dataset_percentile_5, 4)), col = "blue", lty = 2)
# Determine the number of bins you want
num_bins <- 100
# Initialize an empty data frame to store the results
sim_5th_percentiles_df <- data.frame(Simulation = character(), Fifth_Percentile = numeric(), stringsAsFactors = FALSE)
# Remove row names from sim_5th_percentiles_df
rownames(sim_5th_percentiles_df) <- NULL
# Loop through each simulation
for (i in seq_along(Simulation_windows_avg_he_3_2)) {
# Create histogram title
histogram_title <- paste("H_e Distribution of Simulation", i, "- Windowsize:", window_size, "bp")
# Create a histogram with custom breaks
hist(Simulation_windows_avg_he_3_2[[i]], breaks = num_bins, main = histogram_title, xlab = "H_e")
# Calculate the 5th percentile
percentile_5 <- quantile(Simulation_windows_avg_he_3_2[[i]], 0.05)
neutral_model_tables[[i]]$H_e_5th_percentile <- percentile_5
# Add the simulation name and the fifth percentile value to the data frame
sim_5th_percentiles_df[i, "Simulation"] <- paste("Simulation", i)
sim_5th_percentiles_df[i, "Fifth_Percentile"] <- percentile_5
# Add a vertical line at the 5th percentile
abline(v = percentile_5, col = "red", lty = 2)
# Add a legend
legend("topright", legend = paste("5th percentile =", round(percentile_5, 4)), col = "red", lty = 2)
}
# Sort the data frame by Fifth_Percentile values in ascending order
sim_5th_percentiles_df <- sim_5th_percentiles_df[order(sim_5th_percentiles_df$Fifth_Percentile), ]
print(sim_5th_percentiles_df)
# Print the data frame
kable(sim_5th_percentiles_df)
# Extract Average_H_e values from all tables in neutral_model_tables
sim_average_H_e_values <- sapply(neutral_model_tables, function(table) table[["Average_H_e"]])
# Determine the number of bins you want
num_bins <- 20
# Create a histogram with custom breaks
hist(sim_average_H_e_values, breaks = num_bins, main = "Average SNP H_e per simulation - Distribution", xlab = "H_e")
# Calculate the 5th percentile
percentile_5_SNP_based_average <- quantile(sim_average_H_e_values, 0.05)
# Add a vertical line at the 5th percentile
abline(v = percentile_5_SNP_based_average, col = "red", lty = 2)
# Add a vertical line at the 5th percentile
abline(v = empirical_dataset_percentile_5, col = "blue", lty = 2)
# Add a legend
legend("topright", legend = paste("5th percentile (Simulated data) =", round(percentile_5_SNP_based_average, 4)), col = "red", lty = 2)
legend("topright", legend = paste("5th percentile (Empirical dataset)=", round(empirical_dataset_percentile_5, 4)), col = "blue", lty = 2)
setwd(output_dir_sweep_test)
# Defining the dataframe that will store the selection testing results
ROH_hotspots_selection_testing <- data.frame(
Name = character(),
Under_selection = character(),
Average_H_e = numeric()
)
for (i in seq_along(empirical_hotspot_tables)) {
# Check if Average_H_e is <= percentile_5 for the current table (ROH-hotspot)
if (empirical_hotspot_tables[[i]][["Average_H_e"]] <= min(sim_5th_percentiles_df$Fifth_Percentile)) {
# # If under selection, append the name and Average_H_e value with "Yes"
ROH_hotspots_selection_testing <- rbind(ROH_hotspots_selection_testing, data.frame(
Name = empirical_hotspot_tables[[i]][["name"]],
Under_selection = "Yes",  # Marking as "Yes" if under selection
Average_H_e = empirical_hotspot_tables[[i]][["Average_H_e"]]
))
} else {
# If not under selection, append the name and Average_H_e value with "No"
ROH_hotspots_selection_testing <- rbind(ROH_hotspots_selection_testing, data.frame(
Name = empirical_hotspot_tables[[i]][["name"]],
Under_selection = "No",  # Marking as "No" if not under selection
Average_H_e = empirical_hotspot_tables[[i]][["Average_H_e"]]
))
}
}
# Sort the data frame by Average_H_e values in ascending order
ROH_hotspots_selection_testing <- ROH_hotspots_selection_testing[order(ROH_hotspots_selection_testing$Average_H_e), ]
# Plot histogram of hotspot Average_H_e values
hist(ROH_hotspots_selection_testing$Average_H_e, breaks = 20, main = "ROH-Hotspots Distribution of Average H_e Values", xlab = "H_e")
# Add a vertical line at the 5th percentile for simulated dataset
abline(v = percentile_5, col = "red", lty = 2)
# Adding legend for the 5th percentile of the simulated dataset
legend("topright", legend = paste("Simulated (5th percentile) =", round(min(sim_5th_percentiles_df$Fifth_Percentile), 4)),
col = "red", lty = 2, cex = 0.8, text.col = "black")
# Add a vertical line at the 5th percentile for empirical dataset
abline(v = empirical_dataset_percentile_5, col = "blue", lty = 2)
# Adding legend for the 5th percentile of the empirical dataset
legend("topleft", legend = paste("Empirical (5th percentile) =", round(empirical_dataset_percentile_5, 4)),
col = "blue", lty = 2, cex = 0.8, text.col = "black")
cat("ROH-hotspot selection testing results:\n")
kable(ROH_hotspots_selection_testing, row.names = FALSE)
# # Saving the results in a .tsv-file
# write.table(ROH_hotspots_selection_testing, "ROH_hotspots_selection_testing_results.tsv", sep = "\t", row.names = FALSE,quote = FALSE)
setwd(output_dir_sweep_test)
# Defining the dataframe that will store the selection testing results
ROH_hotspots_selection_testing <- data.frame(
Name = character(),
Under_selection = character(),
Average_H_e = numeric()
)
for (i in seq_along(empirical_hotspot_tables)) {
# Check if Average_H_e is <= percentile_5 for the current table (ROH-hotspot)
if (empirical_hotspot_tables[[i]][["Average_H_e"]] <= min(sim_5th_percentiles_df$Fifth_Percentile)) {
# # If under selection, append the name and Average_H_e value with "Yes"
ROH_hotspots_selection_testing <- rbind(ROH_hotspots_selection_testing, data.frame(
Name = empirical_hotspot_tables[[i]][["name"]],
Under_selection = "Yes",  # Marking as "Yes" if under selection
Average_H_e = empirical_hotspot_tables[[i]][["Average_H_e"]]
))
} else {
# If not under selection, append the name and Average_H_e value with "No"
ROH_hotspots_selection_testing <- rbind(ROH_hotspots_selection_testing, data.frame(
Name = empirical_hotspot_tables[[i]][["name"]],
Under_selection = "No",  # Marking as "No" if not under selection
Average_H_e = empirical_hotspot_tables[[i]][["Average_H_e"]]
))
}
}
# Sort the data frame by Average_H_e values in ascending order
ROH_hotspots_selection_testing <- ROH_hotspots_selection_testing[order(ROH_hotspots_selection_testing$Average_H_e), ]
# Plot histogram of hotspot Average_H_e values
hist(ROH_hotspots_selection_testing$Average_H_e, breaks = 20, main = "ROH-Hotspots Distribution of Average H_e Values", xlab = "H_e")
# Add a vertical line at the 5th percentile for simulated dataset
abline(v = min(sim_5th_percentiles_df$Fifth_Percentile), col = "red", lty = 2)
# Adding legend for the 5th percentile of the simulated dataset
legend("topright", legend = paste("Simulated (5th percentile) =", round(min(sim_5th_percentiles_df$Fifth_Percentile), 4)),
col = "red", lty = 2, cex = 0.8, text.col = "black")
# Add a vertical line at the 5th percentile for empirical dataset
abline(v = empirical_dataset_percentile_5, col = "blue", lty = 2)
# Adding legend for the 5th percentile of the empirical dataset
legend("topleft", legend = paste("Empirical (5th percentile) =", round(empirical_dataset_percentile_5, 4)),
col = "blue", lty = 2, cex = 0.8, text.col = "black")
cat("ROH-hotspot selection testing results:\n")
kable(ROH_hotspots_selection_testing, row.names = FALSE)
# # Saving the results in a .tsv-file
# write.table(ROH_hotspots_selection_testing, "ROH_hotspots_selection_testing_results.tsv", sep = "\t", row.names = FALSE,quote = FALSE)
